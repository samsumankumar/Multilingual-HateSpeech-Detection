{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"mBERT_multilingual.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-u2JgtiSYQiO","executionInfo":{"status":"ok","timestamp":1604873562425,"user_tz":300,"elapsed":47631,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}},"outputId":"488dd2fb-7421-453b-cd1e-08c225ba1e25","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hG52WywReczh","executionInfo":{"status":"ok","timestamp":1604873589330,"user_tz":300,"elapsed":9807,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}},"outputId":"a50e583b-e6bb-4590-9a5c-6eb97dff557f","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install pytorch-pretrained-bert pytorch-nlp"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n","\u001b[?25hCollecting pytorch-nlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n","\u001b[K     |████████████████████████████████| 92kB 6.3MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.7.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/54/099a2ea5d4b2d5931a26f280a7585f613b1fafaac9189e489a9e25004a01/boto3-1.16.13-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 8.5MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.7)\n","Collecting botocore<1.20.0,>=1.19.13\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/40/b5e681d80dc46bafd0dc2e55266190cc432dfd5b72b9e7e1c5743aa6c362/botocore-1.19.13-py2.py3-none-any.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 8.8MB/s \n","\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.5MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3->pytorch-pretrained-bert) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.13->boto3->pytorch-pretrained-bert) (1.15.0)\n","\u001b[31mERROR: botocore 1.19.13 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, pytorch-nlp\n","Successfully installed boto3-1.16.13 botocore-1.19.13 jmespath-0.10.0 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7A8Wt1WgeMUz","executionInfo":{"status":"ok","timestamp":1604873594889,"user_tz":300,"elapsed":15029,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}},"outputId":"d3511851-475c-47fc-82dc-698509625f2d","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import tensorflow as tf\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertAdam, BertForSequenceClassification\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score, accuracy_score\n","from statistics import mode\n","\n","import warnings\n","\n","warnings.simplefilter(\"ignore\", UserWarning)\n","warnings.simplefilter(\"ignore\", FutureWarning)\n","warnings.simplefilter(\"ignore\", DeprecationWarning)\n","\n","# specify GPU device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"w264IlP9ghob","executionInfo":{"status":"ok","timestamp":1604873594892,"user_tz":300,"elapsed":14662,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}}},"source":["def train_validate_split(df,seed=42,validate_percent = 0.1):\n","  train, validate = train_test_split(df, test_size=validate_percent, stratify=df['label'])\n","  return train, validate\n","\n","def train_validate_test_split(df,seed, train_percent=.8, validate_percent=.125):\n","  train, test = train_test_split(df, train_size=train_percent, stratify=df['label'])\n","  train, validate = train_test_split(train, test_size=validate_percent, stratify=train['label'])\n","  return train, validate, test\n","\n","def sample_data(df,sample,seed):\n","    X_train, _, y_train, _ = train_test_split( df['tweet'], df['label'], train_size=sample, random_state=seed, stratify=df['label'])\n","    return pd.concat([X_train,y_train], axis = 1 )\n","\n","def tokenize_data(df):\n","    sentences = [\"[CLS] \" + query + \" [SEP]\" for query in df['tweet']]\n","    # Tokenize with multilingual BERT tokenizer\n","    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","    MAX_LEN = 128\n","\n","    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n","    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n","                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","    # Create attention masks\n","    attention_masks = []\n","    # Create a mask of 1s for each token followed by 0s for padding\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","    return input_ids, attention_masks\n","\n","def Data_Loader(inputs_ids, attention_masks, df, batch_size=16):\n","    data = TensorDataset(torch.LongTensor(inputs_ids), torch.LongTensor(attention_masks), torch.LongTensor(df['label'].values))\n","    dataloader = DataLoader(data, sampler=RandomSampler(data), batch_size=batch_size)\n","    return dataloader"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"lRd06Ne4ghq5","executionInfo":{"status":"ok","timestamp":1604873594896,"user_tz":300,"elapsed":14280,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}}},"source":["def model_train(model, train_dataloader, validation_dataloader):\n","    # Store our loss and accuracy for plotting\n","    train_loss_set = []\n","    # BERT training loop\n","    epochs = 3\n","    for _ in trange(epochs, desc=\"Epoch\"):  \n","        # Set our model to training mode\n","        model.train()\n","        # Tracking variables\n","        tr_loss = 0\n","        nb_tr_examples, nb_tr_steps = 0, 0\n","        # Train the data for one epoch\n","        for step, batch in enumerate(train_dataloader):\n","            # Add batch to GPU\n","            batch = tuple(t.to(device) for t in batch)\n","            # Unpack the inputs from our dataloader\n","            b_input_ids, b_input_mask, b_labels = batch\n","            # Clear out the gradients (by default they accumulate)\n","            optimizer.zero_grad()\n","            # Forward pass\n","            loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","            train_loss_set.append(loss.item())    \n","            # Backward pass\n","            loss.backward()\n","            # Update parameters and take a step using the computed gradient\n","            optimizer.step()\n","            # Update tracking variables\n","            tr_loss += loss.item()\n","            nb_tr_examples += b_input_ids.size(0)\n","            nb_tr_steps += 1\n","        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","\n","        ## VALIDATION\n","\n","        # Put model in evaluation mode\n","        model.eval()\n","        # Tracking variables \n","        eval_loss, eval_accuracy = 0, 0\n","        nb_eval_steps, nb_eval_examples = 0, 0\n","        # Evaluate data for one epoch\n","        for batch in validation_dataloader:\n","            # Add batch to GPU\n","            batch = tuple(t.to(device) for t in batch)\n","            # Unpack the inputs from our dataloader\n","            b_input_ids, b_input_mask, b_labels = batch\n","            # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","            with torch.no_grad():\n","                # Forward pass, calculate logit predictions\n","                logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)    \n","            # Move logits and labels to CPU\n","            logits = logits.detach().cpu().numpy()\n","            label_ids = b_labels.to('cpu').numpy()\n","            tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n","            eval_accuracy += tmp_eval_accuracy\n","            nb_eval_steps += 1\n","        validation_accuracy = (eval_accuracy/nb_eval_steps)\n","        print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","    return validation_accuracy"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"OsnuBqImghv2","executionInfo":{"status":"ok","timestamp":1604873594899,"user_tz":300,"elapsed":13875,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}}},"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","def model_test(model,prediction_dataloader):\n","    model.eval()\n","    # Tracking variables \n","    predictions , true_labels = [], []\n","# Predict \n","    for batch in prediction_dataloader:\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        predictions+=list(np.argmax(logits, axis=1).flatten())\n","        true_labels+=list(label_ids.flatten())\n","\n","    test_f1_score = f1_score(true_labels, predictions, average= 'macro')\n","    print(\"Macro F1 Score:\",test_f1_score)\n","    test_accuracy_score = accuracy_score(true_labels, predictions)\n","    print(\"Accuracy score:\", test_accuracy_score, \"\\n\")\n","    print(\"=\"*100)\n","    return test_f1_score"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLCuCukimkNk","executionInfo":{"status":"ok","timestamp":1604873594902,"user_tz":300,"elapsed":11010,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}}},"source":["def model_initialise(path= None , use_saved_model=False):\n","  # Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n","  model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=2).cuda()\n","\n","  param_optimizer = list(model.named_parameters())\n","  no_decay = ['bias', 'gamma', 'beta']\n","  optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}]\n","\n","  optimizer = BertAdam(optimizer_grouped_parameters, lr=2e-5, warmup=.1)\n","  \n","  if(use_saved_model==True):\n","    checkpoint = torch.load(path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","  return model, optimizer"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"CBxfdamsdX0r","executionInfo":{"status":"ok","timestamp":1604881851246,"user_tz":300,"elapsed":661,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}}},"source":["languages = {'en_fr':'Arabic','fr_ar':'English','en_ar':'French'} \n","directory = './'\n","drive_directory = '/content/drive/My Drive/Multilingual models' \n","for lang1, lang2 in languages.items():\n","\tdf = pd.read_csv(os.path.join(directory, lang1+'.csv'))\n","\ttrain_df, validation_df = train_validate_split(df)\n","\ttrain_input_ids, train_attention_masks = tokenize_data(train_df)\n","\ttrain_dataloader = Data_Loader(train_input_ids, train_attention_masks, train_df)\n","\tvalidation_input_ids, validation_attention_masks = tokenize_data(validation_df)\n","\tvalidation_dataloader = Data_Loader(validation_input_ids, validation_attention_masks, validation_df)\n","\tmodel, optimizer = model_initialise()\n","\tvalidation_accuracy = model_train(model, train_dataloader, validation_dataloader)\n","\tfname = 'mBERT'+lang2+'.pth'\n","\tpath = os.path.join(drive_directory, fname)\n","\ttorch.save({'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict()}, path)\n","\ttest_df = pd.read_csv(os.path.join(directory, lang2+'.csv'))\n","\ttest_input_ids, test_attention_masks = tokenize_data(test_df)\n","\ttest_dataloader = Data_Loader(test_input_ids, test_attention_masks, test_df)\n","\tprint(\"\\nZero Shot Model for test:\",lang2,'\\n')\n","\tzero_shot_score = model_test(model, test_dataloader)\n","\tsample_sizes = [16, 32, 64, 128, 256]\n","\tfor sample in sample_sizes:\n","\t\tdf = pd.read_csv(os.path.join(directory, lang2+'.csv'))\n","\t\tseeds = [2018, 2019, 2020, 2021, 2022]\n","\t\tscores=[]\n","\t\tfor seed in seeds:\n","\t\t\tnp.random.seed(seed)\n","\t\t\ttrain_df, validation_df, test_df = train_validate_test_split(df,seed)\n","\t\t\ttrain_len = len(train_df)\n","\t\t\tif sample==256 and seed==2022:\n","\t\t\t    sample_sizes.append(train_len)\n","\t\t\tif sample == train_len and seed == 2022:\n","\t\t\t    sample_sizes.remove(train_len)\n","\t\t\tmodel, optimizer = model_initialise(path,use_saved_model=True)\n","\t\t\tif (sample != train_len):\n","\t\t\t\ttrain_df_sample = sample_data(train_df,sample,seed)\n","\t\t\t\ttrain_input_ids, train_attention_masks = tokenize_data(train_df_sample)\n","\t\t\t\ttrain_dataloader = Data_Loader(train_input_ids, train_attention_masks, train_df_sample)\n","\t\t\telse:\n","\t\t\t\ttrain_input_ids, train_attention_masks = tokenize_data(train_df)\n","\t\t\t\ttrain_dataloader = Data_Loader(train_input_ids, train_attention_masks, train_df)\n","\n","\t\t\tvalidation_input_ids, validation_attention_masks = tokenize_data(validation_df)\n","\t\t\tvalidation_dataloader = Data_Loader(validation_input_ids, validation_attention_masks, validation_df)\n","\t\t\tprint(\"\\nModel Summary:\")\n","\t\t\tprint('Language:', lang2)\n","\t\t\tprint('Sample Size:', sample)\n","\t\t\tprint('Seed value:', seed)\n","\t\t\tvalidation_accuracy = model_train(model, train_dataloader, validation_dataloader)\n","\t\t\ttest_input_ids, test_attention_masks = tokenize_data(test_df)\n","\t\t\ttest_dataloader = Data_Loader(test_input_ids, test_attention_masks, test_df)\n","\t\t\tscores.append(model_test(model, test_dataloader))\n","\t\tprint(\"\\nThe Average F1-Score of\",lang2,\"for the sample size\",sample,\"is:\",sum(scores)/len(scores))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"hDOC67WglteR"},"source":["# 100%|██████████| 871891/871891 [00:00<00:00, 2036519.43B/s]\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# 100%|██████████| 623743758/623743758 [00:21<00:00, 28919379.27B/s]\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]Train loss: 0.35031267179318726\n","# Epoch:  33%|███▎      | 1/3 [24:09<48:19, 1449.51s/it]Validation Accuracy: 0.8565821256038648\n","# Train loss: 0.32770233828394957\n","# Epoch:  67%|██████▋   | 2/3 [48:24<24:11, 1451.21s/it]Validation Accuracy: 0.8531151091121106\n","# Train loss: 0.3251827644762679\n","# Epoch: 100%|██████████| 3/3 [1:12:41<00:00, 1453.91s/it]Validation Accuracy: 0.8629122938530734\n","\n","\n","# Zero Shot Model for test: Arabic \n","\n","# Macro F1 Score: 0.4417945823357679\n","# Accuracy score: 0.7888735314443677 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 16\n","# Seed value: 2018\n","# Train loss: 0.4877600073814392\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.17s/it]Validation Accuracy: 0.7921195652173914\n","# Train loss: 0.43853458762168884\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.18s/it]Validation Accuracy: 0.7853260869565217\n","# Train loss: 0.31721967458724976\n","# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.18s/it]Validation Accuracy: 0.7948369565217391\n","\n","# Macro F1 Score: 0.44512784258277366\n","# Accuracy score: 0.7892918825561313 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 16\n","# Seed value: 2019\n","# Train loss: 0.3746156692504883\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.15s/it]Validation Accuracy: 0.7839673913043478\n","# Train loss: 0.4709932208061218\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.15s/it]Validation Accuracy: 0.7758152173913043\n","# Train loss: 0.44868525862693787\n","# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.15s/it]Validation Accuracy: 0.782608695652174\n","\n","# Macro F1 Score: 0.4405797101449275\n","# Accuracy score: 0.7875647668393783 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 16\n","# Seed value: 2020\n","# Train loss: 0.537870466709137\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.14s/it]Validation Accuracy: 0.7880434782608695\n","# Train loss: 0.5740197896957397\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.15s/it]Validation Accuracy: 0.7921195652173914\n","# Train loss: 0.48160475492477417\n","# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.16s/it]Validation Accuracy: 0.7907608695652174\n","\n","# Macro F1 Score: 0.44484123645172713\n","# Accuracy score: 0.7884283246977547 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 16\n","# Seed value: 2021\n","# Train loss: 0.6358118653297424\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.17s/it]Validation Accuracy: 0.7921195652173914\n","# Train loss: 0.5365766882896423\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.16s/it]Validation Accuracy: 0.7921195652173914\n","# Train loss: 0.5496635437011719\n","# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.16s/it]Validation Accuracy: 0.7921195652173914\n","\n","# Macro F1 Score: 0.4445545017782492\n","# Accuracy score: 0.7875647668393783 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 16\n","# Seed value: 2022\n","# Train loss: 0.5506600141525269\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.14s/it]Validation Accuracy: 0.7880434782608695\n","# Train loss: 0.6158686876296997\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.14s/it]Validation Accuracy: 0.7866847826086957\n","# Train loss: 0.45166030526161194\n","# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.15s/it]Validation Accuracy: 0.7907608695652174\n","\n","# Macro F1 Score: 0.4405797101449275\n","# Accuracy score: 0.7875647668393783 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of Arabic for the sample size 16 is: 0.443136600220521\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 32\n","# Seed value: 2018\n","# Train loss: 0.47631022334098816\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.39s/it]Validation Accuracy: 0.7894021739130435\n","# Train loss: 0.39869584143161774\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.39s/it]Validation Accuracy: 0.7894021739130435\n","# Train loss: 0.39814023673534393\n","# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it]Validation Accuracy: 0.782608695652174\n","\n","# Macro F1 Score: 0.4642141990291262\n","# Accuracy score: 0.7892918825561313 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 32\n","# Seed value: 2019\n","# Train loss: 0.677393764257431\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.38s/it]Validation Accuracy: 0.7880434782608695\n","# Train loss: 0.5702735483646393\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.38s/it]Validation Accuracy: 0.779891304347826\n","# Train loss: 0.5174460858106613\n","# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it]Validation Accuracy: 0.7839673913043478\n","\n","# Macro F1 Score: 0.46017067671318895\n","# Accuracy score: 0.7884283246977547 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 32\n","# Seed value: 2020\n","# Train loss: 0.5345990210771561\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.40s/it]Validation Accuracy: 0.7934782608695652\n","# Train loss: 0.4911712408065796\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.40s/it]Validation Accuracy: 0.7961956521739131\n","# Train loss: 0.46835319697856903\n","# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]Validation Accuracy: 0.7921195652173914\n","\n","# Macro F1 Score: 0.45509795658426605\n","# Accuracy score: 0.7849740932642487 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 32\n","# Seed value: 2021\n","# Train loss: 0.6761367321014404\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.39s/it]Validation Accuracy: 0.779891304347826\n","# Train loss: 0.42713192105293274\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.39s/it]Validation Accuracy: 0.7880434782608695\n","# Train loss: 0.5124907940626144\n","# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]Validation Accuracy: 0.7894021739130435\n","\n","# Macro F1 Score: 0.4753586710294488\n","# Accuracy score: 0.7901554404145078 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 32\n","# Seed value: 2022\n","# Train loss: 0.6386280953884125\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.40s/it]Validation Accuracy: 0.782608695652174\n","# Train loss: 0.5096715986728668\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.40s/it]Validation Accuracy: 0.7771739130434783\n","# Train loss: 0.5280434042215347\n","# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.39s/it]Validation Accuracy: 0.78125\n","\n","# Macro F1 Score: 0.4442676365840721\n","# Accuracy score: 0.7867012089810017 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of Arabic for the sample size 32 is: 0.45982182798802046\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 64\n","# Seed value: 2018\n","# Train loss: 0.5445476695895195\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.86s/it]Validation Accuracy: 0.7894021739130435\n","# Train loss: 0.530044287443161\n","# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.86s/it]Validation Accuracy: 0.7934782608695652\n","# Train loss: 0.4286636412143707\n","# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.86s/it]Validation Accuracy: 0.7894021739130435\n","\n","# Macro F1 Score: 0.44512784258277366\n","# Accuracy score: 0.7892918825561313 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 64\n","# Seed value: 2019\n","# Train loss: 0.6089915484189987\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.87s/it]Validation Accuracy: 0.78125\n","# Train loss: 0.5037054270505905\n","# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.87s/it]Validation Accuracy: 0.7948369565217391\n","# Train loss: 0.4557698369026184\n","# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.86s/it]Validation Accuracy: 0.7853260869565217\n","\n","# Macro F1 Score: 0.44484123645172713\n","# Accuracy score: 0.7884283246977547 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 64\n","# Seed value: 2020\n","# Train loss: 0.5609106048941612\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.85s/it]Validation Accuracy: 0.7907608695652174\n","# Train loss: 0.5048648715019226\n","# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.85s/it]Validation Accuracy: 0.7866847826086957\n","# Train loss: 0.4291808754205704\n","# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.86s/it]Validation Accuracy: 0.7853260869565217\n","\n","# Macro F1 Score: 0.44084983099951713\n","# Accuracy score: 0.7884283246977547 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 64\n","# Seed value: 2021\n","# Train loss: 0.5369466841220856\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.87s/it]Validation Accuracy: 0.7921195652173914\n","# Train loss: 0.55982705950737\n","# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.86s/it]Validation Accuracy: 0.7934782608695652\n","# Train loss: 0.49174918234348297\n","# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.86s/it]Validation Accuracy: 0.779891304347826\n","\n","# Macro F1 Score: 0.4490703188369626\n","# Accuracy score: 0.7892918825561313 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 64\n","# Seed value: 2022\n","# Train loss: 0.5853915736079216\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.86s/it]Validation Accuracy: 0.7866847826086957\n","# Train loss: 0.5579991340637207\n","# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.86s/it]Validation Accuracy: 0.7948369565217391\n","# Train loss: 0.47996123880147934\n","# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.86s/it]Validation Accuracy: 0.7866847826086957\n","\n","# Macro F1 Score: 0.44084983099951713\n","# Accuracy score: 0.7884283246977547 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of Arabic for the sample size 64 is: 0.44414781197409947\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 128\n","# Seed value: 2018\n","# Train loss: 0.5351656377315521\n","# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.83s/it]Validation Accuracy: 0.7880434782608695\n","# Train loss: 0.4358520284295082\n","# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.82s/it]Validation Accuracy: 0.779891304347826\n","# Train loss: 0.4474550224840641\n","# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.81s/it]Validation Accuracy: 0.7989130434782609\n","\n","# Macro F1 Score: 0.520943651433176\n","# Accuracy score: 0.8013816925734024 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 128\n","# Seed value: 2019\n","# Train loss: 0.5876385718584061\n","# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.80s/it]Validation Accuracy: 0.78125\n","# Train loss: 0.4993381015956402\n","# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.79s/it]Validation Accuracy: 0.7880434782608695\n","# Train loss: 0.4376717023551464\n","# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.79s/it]Validation Accuracy: 0.7975543478260869\n","\n","# Macro F1 Score: 0.4769815727857012\n","# Accuracy score: 0.7936096718480138 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 128\n","# Seed value: 2020\n","# Train loss: 0.4564414247870445\n","# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.79s/it]Validation Accuracy: 0.7948369565217391\n","# Train loss: 0.4572427049279213\n","# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.80s/it]Validation Accuracy: 0.7921195652173914\n","# Train loss: 0.28521990310400724\n","# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.80s/it]Validation Accuracy: 0.8274456521739131\n","\n","# Macro F1 Score: 0.6579425211006367\n","# Accuracy score: 0.8298791018998273 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 128\n","# Seed value: 2021\n","# Train loss: 0.5158258713781834\n","# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.80s/it]Validation Accuracy: 0.782608695652174\n","# Train loss: 0.4578445926308632\n","# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.80s/it]Validation Accuracy: 0.7921195652173914\n","# Train loss: 0.36842665262520313\n","# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.81s/it]Validation Accuracy: 0.8002717391304348\n","\n","# Macro F1 Score: 0.49647308918736105\n","# Accuracy score: 0.7979274611398963 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 128\n","# Seed value: 2022\n","# Train loss: 0.550058402121067\n","# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.83s/it]Validation Accuracy: 0.7866847826086957\n","# Train loss: 0.45853661745786667\n","# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.82s/it]Validation Accuracy: 0.7880434782608695\n","# Train loss: 0.4035132862627506\n","# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.82s/it]Validation Accuracy: 0.811141304347826\n","\n","# Macro F1 Score: 0.5821629165673827\n","# Accuracy score: 0.8169257340241797 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of Arabic for the sample size 128 is: 0.5469007502148515\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 256\n","# Seed value: 2018\n","# Train loss: 0.5149418320506811\n","# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.70s/it]Validation Accuracy: 0.7921195652173914\n","# Train loss: 0.4195546731352806\n","# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.70s/it]Validation Accuracy: 0.8179347826086957\n","# Train loss: 0.3504837276414037\n","# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.71s/it]Validation Accuracy: 0.8274456521739131\n","\n","# Macro F1 Score: 0.7182855626326963\n","# Accuracy score: 0.8290155440414507 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 256\n","# Seed value: 2019\n","# Train loss: 0.5347324442118406\n","# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.74s/it]Validation Accuracy: 0.7880434782608695\n","# Train loss: 0.44904034584760666\n","# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.74s/it]Validation Accuracy: 0.8165760869565217\n","# Train loss: 0.33564471430145204\n","# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.73s/it]Validation Accuracy: 0.8274456521739131\n","\n","# Macro F1 Score: 0.6917192097519966\n","# Accuracy score: 0.8359240069084629 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 256\n","# Seed value: 2020\n","# Train loss: 0.508904873393476\n","# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.75s/it]Validation Accuracy: 0.7934782608695652\n","# Train loss: 0.37521744426339865\n","# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.74s/it]Validation Accuracy: 0.8274456521739131\n","# Train loss: 0.31107282917946577\n","# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.73s/it]Validation Accuracy: 0.84375\n","\n","# Macro F1 Score: 0.7027720739219712\n","# Accuracy score: 0.8411053540587219 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 256\n","# Seed value: 2021\n","# Train loss: 0.47822216898202896\n","# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.74s/it]Validation Accuracy: 0.7921195652173914\n","# Train loss: 0.37390390131622553\n","# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.75s/it]Validation Accuracy: 0.8233695652173914\n","# Train loss: 0.27208448480814695\n","# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.75s/it]Validation Accuracy: 0.8097826086956522\n","\n","# Macro F1 Score: 0.5948454012765513\n","# Accuracy score: 0.8151986183074266 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 256\n","# Seed value: 2022\n","# Train loss: 0.523190813139081\n","# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.74s/it]Validation Accuracy: 0.7907608695652174\n","# Train loss: 0.3772939518094063\n","# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.74s/it]Validation Accuracy: 0.8220108695652174\n","# Train loss: 0.29486718913540244\n","# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.73s/it]Validation Accuracy: 0.8288043478260869\n","\n","# Macro F1 Score: 0.7225017972681524\n","# Accuracy score: 0.844559585492228 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of Arabic for the sample size 256 is: 0.6860248089702736\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 4051\n","# Seed value: 2018\n","# Train loss: 0.3981095462426402\n","# Epoch:  33%|███▎      | 1/3 [01:16<02:33, 76.85s/it]Validation Accuracy: 0.8790760869565217\n","# Train loss: 0.31772420958436626\n","# Epoch:  67%|██████▋   | 2/3 [02:33<01:16, 76.93s/it]Validation Accuracy: 0.8872282608695652\n","# Train loss: 0.287292120707947\n","# Epoch: 100%|██████████| 3/3 [03:51<00:00, 77.10s/it]Validation Accuracy: 0.8885869565217391\n","\n","# Macro F1 Score: 0.8153414295033572\n","# Accuracy score: 0.8955094991364422 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 4051\n","# Seed value: 2019\n","# Train loss: 0.4046933833591946\n","# Epoch:  33%|███▎      | 1/3 [01:16<02:33, 76.83s/it]Validation Accuracy: 0.8709239130434783\n","# Train loss: 0.3386469119307747\n","# Epoch:  67%|██████▋   | 2/3 [02:33<01:16, 76.89s/it]Validation Accuracy: 0.8695652173913043\n","# Train loss: 0.2992549875063663\n","# Epoch: 100%|██████████| 3/3 [03:51<00:00, 77.03s/it]Validation Accuracy: 0.8627717391304348\n","\n","# Macro F1 Score: 0.8607503607503607\n","# Accuracy score: 0.9101899827288429 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 4051\n","# Seed value: 2020\n","# Train loss: 0.41032994804134126\n","# Epoch:  33%|███▎      | 1/3 [01:17<02:35, 77.59s/it]Validation Accuracy: 0.8682065217391305\n","# Train loss: 0.3320006223906666\n","# Epoch:  67%|██████▋   | 2/3 [02:35<01:17, 77.75s/it]Validation Accuracy: 0.8872282608695652\n","# Train loss: 0.3045483290773085\n","# Epoch: 100%|██████████| 3/3 [03:53<00:00, 77.90s/it]Validation Accuracy: 0.8953804347826086\n","\n","# Macro F1 Score: 0.8736524227353839\n","# Accuracy score: 0.9196891191709845 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 4051\n","# Seed value: 2021\n","# Train loss: 0.39447353780269623\n","# Epoch:  33%|███▎      | 1/3 [01:17<02:35, 77.87s/it]Validation Accuracy: 0.8804347826086957\n","# Train loss: 0.3118106427158843\n","# Epoch:  67%|██████▋   | 2/3 [02:36<01:17, 77.96s/it]Validation Accuracy: 0.8845108695652174\n","# Train loss: 0.28322701206965495\n","# Epoch: 100%|██████████| 3/3 [03:54<00:00, 78.08s/it]Validation Accuracy: 0.8817934782608695\n","\n","# Macro F1 Score: 0.8452816109629377\n","# Accuracy score: 0.9084628670120898 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: Arabic\n","# Sample Size: 4051\n","# Seed value: 2022\n","# Train loss: 0.3950808967701644\n","# Epoch:  33%|███▎      | 1/3 [01:18<02:36, 78.18s/it]Validation Accuracy: 0.8600543478260869\n","# Train loss: 0.3283273592379755\n","# Epoch:  67%|██████▋   | 2/3 [02:36<01:18, 78.23s/it]Validation Accuracy: 0.8777173913043478\n","# Train loss: 0.29545282330422745\n","# Epoch: 100%|██████████| 3/3 [03:54<00:00, 78.23s/it]Validation Accuracy: 0.8722826086956522\n","\n","# Macro F1 Score: 0.8237897505996441\n","# Accuracy score: 0.8981001727115717 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of Arabic for the sample size 4051 is: 0.8437631149103367"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u21eNhGyqkpX"},"source":["# 100%|██████████| 623743758/623743758 [00:24<00:00, 25124460.61B/s]\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]Train loss: 0.43113599793065954\n","# Epoch:  33%|███▎      | 1/3 [01:39<03:19, 99.86s/it]Validation Accuracy: 0.849868881118881\n","# Train loss: 0.32142672359566143\n","# Epoch:  67%|██████▋   | 2/3 [03:19<01:39, 99.87s/it]Validation Accuracy: 0.8536931818181818\n","# Train loss: 0.26929735707802865\n","# Epoch: 100%|██████████| 3/3 [04:59<00:00, 99.95s/it]Validation Accuracy: 0.8448426573426573\n","\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","\n","# Zero Shot Model for test: English \n","\n","# Macro F1 Score: 0.4831627812546718\n","# Accuracy score: 0.8005710166372622 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 16\n","# Seed value: 2018\n","# Train loss: 0.4099963903427124\n","# Epoch:  33%|███▎      | 1/3 [00:34<01:09, 34.96s/it]Validation Accuracy: 0.8023775375110326\n","# Train loss: 0.40801510214805603\n","# Epoch:  67%|██████▋   | 2/3 [01:09<00:34, 34.96s/it]Validation Accuracy: 0.8029843336275375\n","# Train loss: 0.40257084369659424\n","# Epoch: 100%|██████████| 3/3 [01:44<00:00, 34.99s/it]Validation Accuracy: 0.8037428287731685\n","\n","# Macro F1 Score: 0.46735720817932624\n","# Accuracy score: 0.8039457459926017 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 16\n","# Seed value: 2019\n","# Train loss: 0.43733009696006775\n","# Epoch:  33%|███▎      | 1/3 [00:34<01:09, 34.97s/it]Validation Accuracy: 0.8028326345984113\n","# Train loss: 0.38114693760871887\n","# Epoch:  67%|██████▋   | 2/3 [01:09<00:34, 34.97s/it]Validation Accuracy: 0.8038945278022948\n","# Train loss: 0.4252425730228424\n","# Epoch: 100%|██████████| 3/3 [01:44<00:00, 34.99s/it]Validation Accuracy: 0.8046530229479258\n","\n","# Macro F1 Score: 0.47027882560675344\n","# Accuracy score: 0.8057004647633501 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 16\n","# Seed value: 2020\n","# Train loss: 0.5467470288276672\n","# Epoch:  33%|███▎      | 1/3 [00:34<01:09, 34.91s/it]Validation Accuracy: 0.8024189099735217\n","# Train loss: 0.5087454915046692\n","# Epoch:  67%|██████▋   | 2/3 [01:09<00:34, 34.93s/it]Validation Accuracy: 0.8041220763459841\n","# Train loss: 0.5010417699813843\n","# Epoch: 100%|██████████| 3/3 [01:44<00:00, 34.97s/it]Validation Accuracy: 0.8054597859664607\n","\n","# Macro F1 Score: 0.462872615156682\n","# Accuracy score: 0.8066015365645451 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 16\n","# Seed value: 2021\n","# Train loss: 0.5551973581314087\n","# Epoch:  33%|███▎      | 1/3 [00:34<01:09, 34.89s/it]Validation Accuracy: 0.8044323698146514\n","# Train loss: 0.445564329624176\n","# Epoch:  67%|██████▋   | 2/3 [01:09<00:34, 34.93s/it]Validation Accuracy: 0.8064734112974404\n","# Train loss: 0.4258171617984772\n","# Epoch: 100%|██████████| 3/3 [01:44<00:00, 34.95s/it]Validation Accuracy: 0.8066664827890556\n","\n","# Macro F1 Score: 0.46602204498269006\n","# Accuracy score: 0.8055107654367827 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 16\n","# Seed value: 2022\n","# Train loss: 0.3632422387599945\n","# Epoch:  33%|███▎      | 1/3 [00:34<01:09, 34.85s/it]Validation Accuracy: 0.8025706090026479\n","# Train loss: 0.28625187277793884\n","# Epoch:  67%|██████▋   | 2/3 [01:09<00:34, 34.84s/it]Validation Accuracy: 0.8045082193292145\n","# Train loss: 0.318490207195282\n","# Epoch: 100%|██████████| 3/3 [01:44<00:00, 34.86s/it]Validation Accuracy: 0.8056804390997353\n","\n","# Macro F1 Score: 0.47638998683388184\n","# Accuracy score: 0.8058901640899174 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of English for the sample size 16 is: 0.4685841361518667\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 32\n","# Seed value: 2018\n","# Train loss: 0.481960654258728\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.07s/it]Validation Accuracy: 0.8046185458958518\n","# Train loss: 0.43791867792606354\n","# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.08s/it]Validation Accuracy: 0.8056390666372462\n","# Train loss: 0.40904052555561066\n","# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.11s/it]Validation Accuracy: 0.8061769086496029\n","\n","# Macro F1 Score: 0.454780586762388\n","# Accuracy score: 0.8065066869012615 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 32\n","# Seed value: 2019\n","# Train loss: 0.40320681035518646\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.10s/it]Validation Accuracy: 0.80408759929391\n","# Train loss: 0.3914676308631897\n","# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.12s/it]Validation Accuracy: 0.8044668468667255\n","# Train loss: 0.3631250932812691\n","# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.14s/it]Validation Accuracy: 0.8038600507502207\n","\n","# Macro F1 Score: 0.4753402626949118\n","# Accuracy score: 0.8045148439723039 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 32\n","# Seed value: 2020\n","# Train loss: 0.47909659147262573\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.15s/it]Validation Accuracy: 0.8035566526919683\n","# Train loss: 0.4376790523529053\n","# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.17s/it]Validation Accuracy: 0.8060596866725508\n","# Train loss: 0.3964773118495941\n","# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.18s/it]Validation Accuracy: 0.8073491284201236\n","\n","# Macro F1 Score: 0.4819843048810956\n","# Accuracy score: 0.8087830788200702 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 32\n","# Seed value: 2021\n","# Train loss: 0.5885375142097473\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.11s/it]Validation Accuracy: 0.8054115180935569\n","# Train loss: 0.534212738275528\n","# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.13s/it]Validation Accuracy: 0.8064389342453664\n","# Train loss: 0.47948476672172546\n","# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.16s/it]Validation Accuracy: 0.8067837047661077\n","\n","# Macro F1 Score: 0.45028432361993304\n","# Accuracy score: 0.8072180593758892 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 32\n","# Seed value: 2022\n","# Train loss: 0.38540011644363403\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.14s/it]Validation Accuracy: 0.804128971756399\n","# Train loss: 0.34513017535209656\n","# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.15s/it]Validation Accuracy: 0.8054597859664607\n","# Train loss: 0.33124737441539764\n","# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.18s/it]Validation Accuracy: 0.806252758164166\n","\n","# Macro F1 Score: 0.4706688844354512\n","# Accuracy score: 0.8071232097126055 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of English for the sample size 32 is: 0.46661167247875585\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 64\n","# Seed value: 2018\n","# Train loss: 0.4707513526082039\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.70s/it]Validation Accuracy: 0.8052942961165048\n","# Train loss: 0.41815243661403656\n","# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.71s/it]Validation Accuracy: 0.8062872352162401\n","# Train loss: 0.3521386571228504\n","# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.70s/it]Validation Accuracy: 0.8038531553398058\n","\n","# Macro F1 Score: 0.47875848186559716\n","# Accuracy score: 0.805083941952006 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 64\n","# Seed value: 2019\n","# Train loss: 0.4334219805896282\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.62s/it]Validation Accuracy: 0.8055976941747572\n","# Train loss: 0.38532813638448715\n","# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.65s/it]Validation Accuracy: 0.8056459620476611\n","# Train loss: 0.2856447622179985\n","# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.68s/it]Validation Accuracy: 0.7887728927625772\n","\n","# Macro F1 Score: 0.5380946352831874\n","# Accuracy score: 0.7863985582851181 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 64\n","# Seed value: 2020\n","# Train loss: 0.4602235108613968\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.73s/it]Validation Accuracy: 0.8062803398058253\n","# Train loss: 0.43965379893779755\n","# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.74s/it]Validation Accuracy: 0.8070802074139453\n","# Train loss: 0.35857948660850525\n","# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.73s/it]Validation Accuracy: 0.8082179501323918\n","\n","# Macro F1 Score: 0.49688905839199765\n","# Accuracy score: 0.8080242815138007 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 64\n","# Seed value: 2021\n","# Train loss: 0.5725987479090691\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.71s/it]Validation Accuracy: 0.8066389011473962\n","# Train loss: 0.4916360303759575\n","# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.70s/it]Validation Accuracy: 0.808452394086496\n","# Train loss: 0.4244931899011135\n","# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.71s/it]Validation Accuracy: 0.8101555604589585\n","\n","# Macro F1 Score: 0.4966334904367956\n","# Accuracy score: 0.8097315754529072 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 64\n","# Seed value: 2022\n","# Train loss: 0.4237774834036827\n","# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.66s/it]Validation Accuracy: 0.805370145631068\n","# Train loss: 0.3782000243663788\n","# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.66s/it]Validation Accuracy: 0.8067423323036188\n","# Train loss: 0.3042933028191328\n","# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.67s/it]Validation Accuracy: 0.8066664827890556\n","\n","# Macro F1 Score: 0.5031211701341662\n","# Accuracy score: 0.8070757848809637 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of English for the sample size 64 is: 0.5026993672223489\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 128\n","# Seed value: 2018\n","# Train loss: 0.4767194427549839\n","# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.61s/it]Validation Accuracy: 0.8067423323036188\n","# Train loss: 0.38964541256427765\n","# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.62s/it]Validation Accuracy: 0.7970680714916152\n","# Train loss: 0.2591676265001297\n","# Epoch: 100%|██████████| 3/3 [01:49<00:00, 36.64s/it]Validation Accuracy: 0.7925584730803178\n","\n","# Macro F1 Score: 0.5825569767206635\n","# Accuracy score: 0.7914730152707958 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 128\n","# Seed value: 2019\n","# Train loss: 0.4817820377647877\n","# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.75s/it]Validation Accuracy: 0.805370145631068\n","# Train loss: 0.3923627510666847\n","# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.74s/it]Validation Accuracy: 0.802763680494263\n","# Train loss: 0.2881836351007223\n","# Epoch: 100%|██████████| 3/3 [01:50<00:00, 36.74s/it]Validation Accuracy: 0.7656663724624889\n","\n","# Macro F1 Score: 0.5910614854290478\n","# Accuracy score: 0.7639666129185242 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 128\n","# Seed value: 2020\n","# Train loss: 0.5083153508603573\n","# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.79s/it]Validation Accuracy: 0.806452725066196\n","# Train loss: 0.426469536498189\n","# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.77s/it]Validation Accuracy: 0.8087213150926743\n","# Train loss: 0.3406222891062498\n","# Epoch: 100%|██████████| 3/3 [01:50<00:00, 36.77s/it]Validation Accuracy: 0.8023085834068844\n","\n","# Macro F1 Score: 0.5679909211623383\n","# Accuracy score: 0.8036611970027506 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 128\n","# Seed value: 2021\n","# Train loss: 0.5590024255216122\n","# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.65s/it]Validation Accuracy: 0.8075835723742277\n","# Train loss: 0.4459077939391136\n","# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.68s/it]Validation Accuracy: 0.8105003309797\n","# Train loss: 0.38894867710769176\n","# Epoch: 100%|██████████| 3/3 [01:50<00:00, 36.74s/it]Validation Accuracy: 0.8051494924977936\n","\n","# Macro F1 Score: 0.5368288583758943\n","# Accuracy score: 0.8042777198140947 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 128\n","# Seed value: 2022\n","# Train loss: 0.48631179705262184\n","# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.78s/it]Validation Accuracy: 0.8069078221535746\n","# Train loss: 0.4277756381779909\n","# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.76s/it]Validation Accuracy: 0.804770244924978\n","# Train loss: 0.29662161506712437\n","# Epoch: 100%|██████████| 3/3 [01:50<00:00, 36.79s/it]Validation Accuracy: 0.8045495917917034\n","\n","# Macro F1 Score: 0.5417470807349343\n","# Accuracy score: 0.8050365171203642 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of English for the sample size 128 is: 0.5640370644845756\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 256\n","# Seed value: 2018\n","# Train loss: 0.46986593399196863\n","# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.64s/it]Validation Accuracy: 0.8078800750220654\n","# Train loss: 0.39221590012311935\n","# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.68s/it]Validation Accuracy: 0.8121690203000883\n","# Train loss: 0.23609184147790074\n","# Epoch: 100%|██████████| 3/3 [01:56<00:00, 38.70s/it]Validation Accuracy: 0.7809121248896734\n","\n","# Macro F1 Score: 0.6205074396979988\n","# Accuracy score: 0.7826519965854121 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 256\n","# Seed value: 2019\n","# Train loss: 0.49670007824897766\n","# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.68s/it]Validation Accuracy: 0.8086730472197705\n","# Train loss: 0.41641145572066307\n","# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.68s/it]Validation Accuracy: 0.8114518976169461\n","# Train loss: 0.2459071557968855\n","# Epoch: 100%|██████████| 3/3 [01:56<00:00, 38.68s/it]Validation Accuracy: 0.8004123455428067\n","\n","# Macro F1 Score: 0.6020433735007277\n","# Accuracy score: 0.8006734326093142 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 256\n","# Seed value: 2020\n","# Train loss: 0.5107050035148859\n","# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.74s/it]Validation Accuracy: 0.8071560569285083\n","# Train loss: 0.4253020389005542\n","# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.77s/it]Validation Accuracy: 0.8109554280670785\n","# Train loss: 0.3137670950964093\n","# Epoch: 100%|██████████| 3/3 [01:56<00:00, 38.78s/it]Validation Accuracy: 0.765183693733451\n","\n","# Macro F1 Score: 0.6088055333806448\n","# Accuracy score: 0.7617376458313573 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 256\n","# Seed value: 2021\n","# Train loss: 0.504175927489996\n","# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.75s/it]Validation Accuracy: 0.8069698808473081\n","# Train loss: 0.43708391953259706\n","# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.75s/it]Validation Accuracy: 0.8086385701676965\n","# Train loss: 0.335963798686862\n","# Epoch: 100%|██████████| 3/3 [01:56<00:00, 38.75s/it]Validation Accuracy: 0.8065630516328332\n","\n","# Macro F1 Score: 0.5577013120218601\n","# Accuracy score: 0.8073603338708147 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 256\n","# Seed value: 2022\n","# Train loss: 0.46283324621617794\n","# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.65s/it]Validation Accuracy: 0.808493766548985\n","# Train loss: 0.38424935657531023\n","# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.67s/it]Validation Accuracy: 0.7937306928508384\n","# Train loss: 0.23871747497469187\n","# Epoch: 100%|██████████| 3/3 [01:56<00:00, 38.75s/it]Validation Accuracy: 0.7959027471315092\n","\n","# Macro F1 Score: 0.597326540679203\n","# Accuracy score: 0.7958360997818458 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of English for the sample size 256 is: 0.5972768398560869\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 73797\n","# Seed value: 2018\n","# Train loss: 0.3506857882674746\n","# Epoch:  33%|███▎      | 1/3 [23:43<47:27, 1423.51s/it]Validation Accuracy: 0.8577476831421006\n","# Train loss: 0.31430662151696137\n","# Epoch:  67%|██████▋   | 2/3 [48:01<23:53, 1433.76s/it]Validation Accuracy: 0.8711730472197705\n","# Train loss: 0.29566357425726403\n","# Epoch: 100%|██████████| 3/3 [1:12:30<00:00, 1450.05s/it]Validation Accuracy: 0.8681804390997353\n","\n","# Macro F1 Score: 0.7789891385811427\n","# Accuracy score: 0.883572038319264 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 73797\n","# Seed value: 2019\n","# Train loss: 0.3500457019882714\n","# Epoch:  33%|███▎      | 1/3 [24:13<48:26, 1453.41s/it]Validation Accuracy: 0.8587061451897616\n","# Train loss: 0.3097635749488438\n","# Epoch:  67%|██████▋   | 2/3 [47:47<24:01, 1441.57s/it]Validation Accuracy: 0.8668220432480142\n","# Train loss: 0.3308915351268758\n","# Epoch: 100%|██████████| 3/3 [1:12:10<00:00, 1443.44s/it]Validation Accuracy: 0.8646499889673434\n","\n","# Macro F1 Score: 0.7669203142683729\n","# Accuracy score: 0.877975908185526 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 73797\n","# Seed value: 2020\n","# Train loss: 0.3477986186194908\n","# Epoch:  33%|███▎      | 1/3 [24:21<48:42, 1461.27s/it]Validation Accuracy: 0.8568443843777582\n","# Train loss: 0.32089542979752483\n","# Epoch:  67%|██████▋   | 2/3 [47:45<24:04, 1444.10s/it]Validation Accuracy: 0.867952890556046\n","# Train loss: 0.3035370297051586\n","# Epoch: 100%|██████████| 3/3 [1:11:50<00:00, 1436.69s/it]Validation Accuracy: 0.8659394307149161\n","\n","# Macro F1 Score: 0.7877455263679541\n","# Accuracy score: 0.8842359859622498 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 73797\n","# Seed value: 2021\n","# Train loss: 0.3459371478615656\n","# Epoch:  33%|███▎      | 1/3 [24:23<48:46, 1463.01s/it]Validation Accuracy: 0.8578235326566637\n","# Train loss: 0.3082692668816198\n","# Epoch:  67%|██████▋   | 2/3 [48:43<24:22, 1462.37s/it]Validation Accuracy: 0.8630157766990292\n","# Train loss: 0.29249108955457914\n","# Epoch: 100%|██████████| 3/3 [1:12:19<00:00, 1446.60s/it]Validation Accuracy: 0.8674150485436893\n","\n","# Macro F1 Score: 0.7982963821494751\n","# Accuracy score: 0.8866546523759841 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: English\n","# Sample Size: 73797\n","# Seed value: 2022\n","# Train loss: 0.34628187021562984\n","# Epoch:  33%|███▎      | 1/3 [23:17<46:35, 1397.87s/it]Validation Accuracy: 0.866704821270962\n","# Train loss: 0.30813515411791315\n","# Epoch:  67%|██████▋   | 2/3 [46:29<23:15, 1395.91s/it]Validation Accuracy: 0.8717453662842013\n","# Train loss: 0.29112401696250223\n","# Epoch: 100%|██████████| 3/3 [1:09:36<00:00, 1392.16s/it]Validation Accuracy: 0.8738622572815534\n","\n","# Macro F1 Score: 0.8298590211537122\n","# Accuracy score: 0.8971829650004742 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of English for the sample size 73797 is: 0.7923620765041315"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"28Ff4kXGrUf3"},"source":["# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]Train loss: 0.3869105575777724\n","# Epoch:  33%|███▎      | 1/3 [25:32<51:05, 1532.85s/it]Validation Accuracy: 0.8497665229885057\n","# Train loss: 0.366231967078741\n","# Epoch:  67%|██████▋   | 2/3 [51:05<25:32, 1532.79s/it]Validation Accuracy: 0.852819683908046\n","# Train loss: 0.37040582375989184\n","# Epoch: 100%|██████████| 3/3 [1:16:38<00:00, 1532.77s/it]Validation Accuracy: 0.8590158045977011\n","\n","\n","# Zero Shot Model for test: French \n","\n","# Macro F1 Score: 0.5720060976816932\n","# Accuracy score: 0.6368852459016393 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 16\n","# Seed value: 2018\n","# Train loss: 0.5113570690155029\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.51it/s]Validation Accuracy: 0.5729166666666667\n","# Train loss: 0.5027264356613159\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]Validation Accuracy: 0.5826388888888889\n","# Train loss: 0.4878215789794922\n","# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]Validation Accuracy: 0.5680555555555555\n","\n","# Macro F1 Score: 0.5727288471530009\n","# Accuracy score: 0.6270491803278688 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 16\n","# Seed value: 2019\n","# Train loss: 0.6387056708335876\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.55it/s]Validation Accuracy: 0.6840277777777778\n","# Train loss: 0.6439587473869324\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.54it/s]Validation Accuracy: 0.6743055555555555\n","# Train loss: 0.643578827381134\n","# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]Validation Accuracy: 0.7027777777777777\n","\n","# Macro F1 Score: 0.5742254000680966\n","# Accuracy score: 0.6639344262295082 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 16\n","# Seed value: 2020\n","# Train loss: 0.5029358863830566\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.56it/s]Validation Accuracy: 0.6826388888888889\n","# Train loss: 0.5442073941230774\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.55it/s]Validation Accuracy: 0.6763888888888889\n","# Train loss: 0.5267144441604614\n","# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]Validation Accuracy: 0.6666666666666667\n","\n","# Macro F1 Score: 0.5350609756097561\n","# Accuracy score: 0.5901639344262295 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 16\n","# Seed value: 2021\n","# Train loss: 0.7695850729942322\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.52it/s]Validation Accuracy: 0.6680555555555555\n","# Train loss: 0.7642257213592529\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Validation Accuracy: 0.6777777777777778\n","# Train loss: 0.8199949264526367\n","# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]Validation Accuracy: 0.6652777777777777\n","\n","# Macro F1 Score: 0.5858355282411472\n","# Accuracy score: 0.6434426229508197 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 16\n","# Seed value: 2022\n","# Train loss: 0.7150052189826965\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.56it/s]Validation Accuracy: 0.6791666666666667\n","# Train loss: 0.7061570286750793\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.56it/s]Validation Accuracy: 0.6854166666666667\n","# Train loss: 0.7688431143760681\n","# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]Validation Accuracy: 0.6965277777777777\n","\n","# Macro F1 Score: 0.5891290726817042\n","# Accuracy score: 0.6475409836065574 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of French for the sample size 16 is: 0.5713959647507411\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 32\n","# Seed value: 2018\n","# Train loss: 0.6156394183635712\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.12it/s]Validation Accuracy: 0.5743055555555555\n","# Train loss: 0.7526137232780457\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.12it/s]Validation Accuracy: 0.5854166666666667\n","# Train loss: 0.6503881216049194\n","# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]Validation Accuracy: 0.5868055555555556\n","\n","# Macro F1 Score: 0.5960512600404684\n","# Accuracy score: 0.6680327868852459 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 32\n","# Seed value: 2019\n","# Train loss: 0.6705072224140167\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.13it/s]Validation Accuracy: 0.6840277777777778\n","# Train loss: 0.705536812543869\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.13it/s]Validation Accuracy: 0.6840277777777778\n","# Train loss: 0.5848736017942429\n","# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]Validation Accuracy: 0.7152777777777778\n","\n","# Macro F1 Score: 0.577394316505228\n","# Accuracy score: 0.6680327868852459 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 32\n","# Seed value: 2020\n","# Train loss: 0.5383942425251007\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.13it/s]Validation Accuracy: 0.6652777777777777\n","# Train loss: 0.5659926980733871\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.13it/s]Validation Accuracy: 0.6527777777777778\n","# Train loss: 0.5585153996944427\n","# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]Validation Accuracy: 0.6541666666666667\n","\n","# Macro F1 Score: 0.5247723099181985\n","# Accuracy score: 0.569672131147541 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 32\n","# Seed value: 2021\n","# Train loss: 0.9283453226089478\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.10it/s]Validation Accuracy: 0.6715277777777777\n","# Train loss: 0.8321980834007263\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.11it/s]Validation Accuracy: 0.6729166666666667\n","# Train loss: 0.7613034248352051\n","# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.11it/s]Validation Accuracy: 0.6715277777777777\n","\n","# Macro F1 Score: 0.5955093904102402\n","# Accuracy score: 0.6762295081967213 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 32\n","# Seed value: 2022\n","# Train loss: 0.6797988414764404\n","# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.13it/s]Validation Accuracy: 0.6902777777777778\n","# Train loss: 0.6923722624778748\n","# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.13it/s]Validation Accuracy: 0.6854166666666667\n","# Train loss: 0.6235540956258774\n","# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]Validation Accuracy: 0.70625\n","\n","# Macro F1 Score: 0.5861143984220907\n","# Accuracy score: 0.6475409836065574 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of French for the sample size 32 is: 0.575968335059245\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 64\n","# Seed value: 2018\n","# Train loss: 0.6459776014089584\n","# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.38s/it]Validation Accuracy: 0.5819444444444445\n","# Train loss: 0.6358266174793243\n","# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.38s/it]Validation Accuracy: 0.5944444444444444\n","# Train loss: 0.5609139576554298\n","# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it]Validation Accuracy: 0.6152777777777778\n","\n","# Macro F1 Score: 0.585939393939394\n","# Accuracy score: 0.6844262295081968 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 64\n","# Seed value: 2019\n","# Train loss: 0.6718596518039703\n","# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.36s/it]Validation Accuracy: 0.7090277777777778\n","# Train loss: 0.6017668321728706\n","# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]Validation Accuracy: 0.6881944444444444\n","# Train loss: 0.6152493357658386\n","# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]Validation Accuracy: 0.7090277777777778\n","\n","# Macro F1 Score: 0.5710685163613258\n","# Accuracy score: 0.6598360655737705 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 64\n","# Seed value: 2020\n","# Train loss: 0.6989657580852509\n","# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.38s/it]Validation Accuracy: 0.6791666666666667\n","# Train loss: 0.6375323385000229\n","# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.38s/it]Validation Accuracy: 0.6840277777777778\n","# Train loss: 0.7017572075128555\n","# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.38s/it]Validation Accuracy: 0.7055555555555555\n","\n","# Macro F1 Score: 0.5300546448087431\n","# Accuracy score: 0.6475409836065574 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 64\n","# Seed value: 2021\n","# Train loss: 0.6795783191919327\n","# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.36s/it]Validation Accuracy: 0.6826388888888889\n","# Train loss: 0.6669764071702957\n","# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.37s/it]Validation Accuracy: 0.6666666666666667\n","# Train loss: 0.6441071331501007\n","# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]Validation Accuracy: 0.7027777777777777\n","\n","# Macro F1 Score: 0.602646822370184\n","# Accuracy score: 0.6762295081967213 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 64\n","# Seed value: 2022\n","# Train loss: 0.7263007014989853\n","# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.37s/it]Validation Accuracy: 0.6868055555555556\n","# Train loss: 0.688442125916481\n","# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.37s/it]Validation Accuracy: 0.7138888888888889\n","# Train loss: 0.645633727312088\n","# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]Validation Accuracy: 0.6965277777777777\n","\n","# Macro F1 Score: 0.5737704918032787\n","# Accuracy score: 0.680327868852459 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of French for the sample size 64 is: 0.5726959738565851\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 128\n","# Seed value: 2018\n","# Train loss: 0.655342735350132\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.38s/it]Validation Accuracy: 0.6513888888888889\n","# Train loss: 0.6174135468900204\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.36s/it]Validation Accuracy: 0.6555555555555556\n","# Train loss: 0.5184967927634716\n","# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.33s/it]Validation Accuracy: 0.6027777777777777\n","\n","# Macro F1 Score: 0.579269592172818\n","# Accuracy score: 0.6352459016393442 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 128\n","# Seed value: 2019\n","# Train loss: 0.8273091316223145\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.27s/it]Validation Accuracy: 0.6458333333333333\n","# Train loss: 0.6768480017781258\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.28s/it]Validation Accuracy: 0.6541666666666667\n","# Train loss: 0.5910334140062332\n","# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.28s/it]Validation Accuracy: 0.6791666666666667\n","\n","# Macro F1 Score: 0.5303609565744719\n","# Accuracy score: 0.7008196721311475 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 128\n","# Seed value: 2020\n","# Train loss: 0.8005371615290642\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.31s/it]Validation Accuracy: 0.6993055555555555\n","# Train loss: 0.6893901415169239\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.31s/it]Validation Accuracy: 0.6680555555555555\n","# Train loss: 0.642815001308918\n","# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.29s/it]Validation Accuracy: 0.7118055555555556\n","\n","# Macro F1 Score: 0.5449459157030958\n","# Accuracy score: 0.6926229508196722 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 128\n","# Seed value: 2021\n","# Train loss: 0.8689212277531624\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.29s/it]Validation Accuracy: 0.6916666666666667\n","# Train loss: 0.7155642993748188\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.28s/it]Validation Accuracy: 0.6729166666666667\n","# Train loss: 0.5929057709872723\n","# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.27s/it]Validation Accuracy: 0.6965277777777777\n","\n","# Macro F1 Score: 0.605474710209287\n","# Accuracy score: 0.7090163934426229 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 128\n","# Seed value: 2022\n","# Train loss: 0.8722350895404816\n","# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.26s/it]Validation Accuracy: 0.6930555555555555\n","# Train loss: 0.7364926487207413\n","# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.26s/it]Validation Accuracy: 0.6680555555555555\n","# Train loss: 0.6496948450803757\n","# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.25s/it]Validation Accuracy: 0.6888888888888889\n","\n","# Macro F1 Score: 0.489272632129775\n","# Accuracy score: 0.6721311475409836 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of French for the sample size 128 is: 0.5498647613578895\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 256\n","# Seed value: 2018\n","# Train loss: 0.7019825987517834\n","# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.16s/it]Validation Accuracy: 0.6604166666666667\n","# Train loss: 0.6009964402765036\n","# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.15s/it]Validation Accuracy: 0.6381944444444445\n","# Train loss: 0.5826615393161774\n","# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.14s/it]Validation Accuracy: 0.6715277777777777\n","\n","# Macro F1 Score: 0.5796578171091447\n","# Accuracy score: 0.7008196721311475 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 256\n","# Seed value: 2019\n","# Train loss: 0.7484750133007765\n","# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.27s/it]Validation Accuracy: 0.6680555555555555\n","# Train loss: 0.6422950867563486\n","# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.27s/it]Validation Accuracy: 0.6777777777777778\n","# Train loss: 0.6350728757679462\n","# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.20s/it]Validation Accuracy: 0.6888888888888889\n","\n","# Macro F1 Score: 0.44949670253384244\n","# Accuracy score: 0.680327868852459 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 256\n","# Seed value: 2020\n","# Train loss: 0.770460058003664\n","# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.19s/it]Validation Accuracy: 0.6666666666666667\n","# Train loss: 0.6244156938046217\n","# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.16s/it]Validation Accuracy: 0.7465277777777778\n","# Train loss: 0.5974505543708801\n","# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.13s/it]Validation Accuracy: 0.7368055555555555\n","\n","# Macro F1 Score: 0.5536166619757951\n","# Accuracy score: 0.680327868852459 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 256\n","# Seed value: 2021\n","# Train loss: 0.7984667364507914\n","# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.18s/it]Validation Accuracy: 0.6826388888888889\n","# Train loss: 0.6605656389147043\n","# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.21s/it]Validation Accuracy: 0.6694444444444445\n","# Train loss: 0.5984538272023201\n","# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.20s/it]Validation Accuracy: 0.7201388888888889\n","\n","# Macro F1 Score: 0.646376811594203\n","# Accuracy score: 0.7377049180327869 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 256\n","# Seed value: 2022\n","# Train loss: 0.7581952400505543\n","# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.17s/it]Validation Accuracy: 0.6777777777777778\n","# Train loss: 0.6467741914093494\n","# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.17s/it]Validation Accuracy: 0.6826388888888889\n","# Train loss: 0.616688396781683\n","# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.17s/it]Validation Accuracy: 0.695138888888889\n","\n","# Macro F1 Score: 0.5788466737371847\n","# Accuracy score: 0.6598360655737705 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of French for the sample size 256 is: 0.561598933390034\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 854\n","# Seed value: 2018\n","# Train loss: 0.6781195357664308\n","# Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.16s/it]Validation Accuracy: 0.6006944444444444\n","# Train loss: 0.6145565398593447\n","# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.19s/it]Validation Accuracy: 0.725\n","# Train loss: 0.5731254535824505\n","# Epoch: 100%|██████████| 3/3 [00:48<00:00, 16.20s/it]Validation Accuracy: 0.6993055555555555\n","\n","# Macro F1 Score: 0.6576339559764974\n","# Accuracy score: 0.7377049180327869 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 854\n","# Seed value: 2019\n","# Train loss: 0.6918660767042815\n","# Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.09s/it]Validation Accuracy: 0.6729166666666667\n","# Train loss: 0.6204586558377565\n","# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.11s/it]Validation Accuracy: 0.6868055555555556\n","# Train loss: 0.6163012954726148\n","# Epoch: 100%|██████████| 3/3 [00:48<00:00, 16.09s/it]Validation Accuracy: 0.6694444444444445\n","\n","# Macro F1 Score: 0.602291810728045\n","# Accuracy score: 0.7295081967213115 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 854\n","# Seed value: 2020\n","# Train loss: 0.6794394445953085\n","# Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.09s/it]Validation Accuracy: 0.7416666666666667\n","# Train loss: 0.6194255218577029\n","# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.06s/it]Validation Accuracy: 0.726388888888889\n","# Train loss: 0.6067674351272299\n","# Epoch: 100%|██████████| 3/3 [00:48<00:00, 16.08s/it]Validation Accuracy: 0.7229166666666667\n","\n","# Macro F1 Score: 0.587744294540411\n","# Accuracy score: 0.7254098360655737 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 854\n","# Seed value: 2021\n","# Train loss: 0.7012832364929256\n","# Epoch:  33%|███▎      | 1/3 [00:15<00:31, 16.00s/it]Validation Accuracy: 0.6631944444444444\n","# Train loss: 0.6275758783319103\n","# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.05s/it]Validation Accuracy: 0.6743055555555555\n","# Train loss: 0.6097398542646152\n","# Epoch: 100%|██████████| 3/3 [00:48<00:00, 16.19s/it]Validation Accuracy: 0.6979166666666667\n","\n","# Macro F1 Score: 0.6244348244348246\n","# Accuracy score: 0.7377049180327869 \n","\n","# ====================================================================================================\n","# t_total value of -1 results in schedule not being applied\n","# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n","# Model Summary:\n","# Language: French\n","# Sample Size: 854\n","# Seed value: 2022\n","# Train loss: 0.6619469825901202\n","# Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.35s/it]Validation Accuracy: 0.6555555555555556\n","# Train loss: 0.609012288833732\n","# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.35s/it]Validation Accuracy: 0.7041666666666667\n","# Train loss: 0.5956740076862165\n","# Epoch: 100%|██████████| 3/3 [00:49<00:00, 16.36s/it]Validation Accuracy: 0.7027777777777777\n","\n","# Macro F1 Score: 0.6397085522015928\n","# Accuracy score: 0.75 \n","\n","# ====================================================================================================\n","\n","# The Average F1-Score of French for the sample size 854 is: 0.6223626875762742"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1oF1gFcsCn2K"},"source":[""],"execution_count":null,"outputs":[]}]}