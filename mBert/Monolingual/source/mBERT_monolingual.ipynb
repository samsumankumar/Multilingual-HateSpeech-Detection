{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "mBERT_monolingual_1ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u2JgtiSYQiO",
        "outputId": "b2194c69-c4ac-46e2-c33d-cfce4370f293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG52WywReczh",
        "outputId": "12369142-8ff9-4f7c-8c2c-a39455c0e20e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.7.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.13 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.19.13)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.13->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.13->boto3->pytorch-pretrained-bert) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A8Wt1WgeMUz",
        "outputId": "d6d9c8db-04cd-46c6-a12a-9ab735db7e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from statistics import mode\n",
        "\n",
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla V100-SXM2-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w264IlP9ghob"
      },
      "source": [
        "def train_validate_test_split(df,seed, train_percent=.8, validate_percent=.125):\n",
        "  train, test = train_test_split(df, train_size=train_percent, stratify=df['label'])\n",
        "  train, validate = train_test_split(df, test_size=validate_percent, stratify=df['label'])\n",
        "  return train, validate, test\n",
        "\n",
        "def sample_data(df,sample,seed):\n",
        "    X_train, _, y_train, _ = train_test_split( df['tweet'], df['label'], train_size=sample, random_state=seed, stratify=df['label'])\n",
        "    return pd.concat([X_train,y_train], axis = 1 )\n",
        "\n",
        "def tokenize_data(df):\n",
        "    sentences = [\"[CLS] \" + query + \" [SEP]\" for query in df['tweet']]\n",
        "    # Tokenize with multilingual BERT tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    # Create attention masks\n",
        "    attention_masks = []\n",
        "    # Create a mask of 1s for each token followed by 0s for padding\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "def Data_Loader(inputs_ids, attention_masks, df,batch_size=16): \n",
        "    data = TensorDataset(torch.LongTensor(inputs_ids), torch.LongTensor(attention_masks), torch.LongTensor(df['label'].values))\n",
        "    sampler = RandomSampler(data)\n",
        "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
        "    return dataloader"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRd06Ne4ghq5"
      },
      "source": [
        "def model_train(model, train_dataloader, validation_dataloader):\n",
        "    # Store our loss and accuracy for plotting\n",
        "    train_loss_set = []\n",
        "    # BERT training loop\n",
        "    epochs = 3\n",
        "    for _ in trange(epochs, desc=\"Epoch\"):  \n",
        "        # Set our model to training mode\n",
        "        model.train()\n",
        "        # Tracking variables\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        # Train the data for one epoch\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            # Clear out the gradients (by default they accumulate)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            train_loss_set.append(loss.item())    \n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            # Update parameters and take a step using the computed gradient\n",
        "            optimizer.step()\n",
        "            # Update tracking variables\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += b_input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "        ## VALIDATION\n",
        "\n",
        "        # Put model in evaluation mode\n",
        "        model.eval()\n",
        "        # Tracking variables \n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            b_input_ids, b_input_mask, b_labels = batch\n",
        "            # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "            with torch.no_grad():\n",
        "                # Forward pass, calculate logit predictions\n",
        "                logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)    \n",
        "            # Move logits and labels to CPU\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "            tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            nb_eval_steps += 1\n",
        "        validation_accuracy = (eval_accuracy/nb_eval_steps)\n",
        "        print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "    return validation_accuracy"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsnuBqImghv2"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def model_test(model,prediction_dataloader):\n",
        "    model.eval()\n",
        "    # Tracking variables \n",
        "    predictions , true_labels = [], []\n",
        "# Predict\n",
        "    for batch in prediction_dataloader:\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate logit predictions\n",
        "            logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        predictions+=list(np.argmax(logits, axis=1).flatten())\n",
        "        true_labels+=list(label_ids.flatten())\n",
        "        # Store predictions and true labels\n",
        "#         predictions.append(logits)\n",
        "#         true_labels.append(label_ids)\n",
        "    test_f1_score = f1_score(true_labels, predictions, average= 'macro')\n",
        "    print(\"Macro F1 Score:\",test_f1_score)\n",
        "    test_accuracy_score = accuracy_score(true_labels, predictions)\n",
        "    print(\"Accuracy score:\", test_accuracy_score, \"\\n\")\n",
        "    print(\"=\"*100)\n",
        "    return test_f1_score"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLCuCukimkNk"
      },
      "source": [
        "def model_initialise():\n",
        "  # Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n",
        "  model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=2)\n",
        "  model.cuda()\n",
        "\n",
        "  param_optimizer = list(model.named_parameters())\n",
        "  no_decay = ['bias', 'gamma', 'beta']\n",
        "  optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "  ]\n",
        "\n",
        "  optimizer = BertAdam(optimizer_grouped_parameters, lr=2e-5, warmup=.1)\n",
        "  return model, optimizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCiYd-UpO_q3"
      },
      "source": [
        "print_stmts= []\n",
        "languages = ['French','English']#,'Arabic'\n",
        "directory = './'\n",
        "for lang in languages:\n",
        "\tdf = pd.read_csv(os.path.join(directory, lang+'.csv'))\n",
        "\tsample_sizes = [16, 32, 64, 128, 256]\n",
        "\tfor sample in sample_sizes: \n",
        "\t\tseeds = [2018,2019, 2020, 2021, 2022]\n",
        "\t\tscores = [] \n",
        "\t\tfor seed in seeds:\n",
        "\t\t\tnp.random.seed(seed)\n",
        "\t\t\ttrain_df, validation_df, test_df = train_validate_test_split(df, seed)\n",
        "\t\t\ttrain_len = len(train_df)\n",
        "\t\t\tif sample==256 and seed==2022:\n",
        "\t\t\t    sample_sizes.append(train_len)\n",
        "\t\t\tif sample == train_len and seed == 2022:\n",
        "\t\t\t    sample_sizes.remove(train_len)\n",
        "\t\t\tmodel, optimizer = model_initialise()\n",
        "\t\t\tif(sample != train_len):  \n",
        "\t\t\t\ttrain_df_sample = sample_data(train_df,sample,seed)\n",
        "\t\t\t\ttrain_input_ids, train_attention_masks = tokenize_data(train_df_sample)\n",
        "\t\t\t\ttrain_dataloader = Data_Loader(train_input_ids, train_attention_masks, train_df_sample)\n",
        "\t\t\telse:\n",
        "\t\t\t\ttrain_input_ids, train_attention_masks = tokenize_data(train_df)\n",
        "\t\t\t\ttrain_dataloader = Data_Loader(train_input_ids, train_attention_masks, train_df)\n",
        "\n",
        "\t\t\tvalidation_input_ids, validation_attention_masks = tokenize_data(validation_df)\n",
        "\t\t\tvalidation_dataloader = Data_Loader(validation_input_ids, validation_attention_masks, validation_df)\n",
        "\t\t\tprint(\"\\nModel Summary:\")\n",
        "\t\t\tprint('Language:', lang)\n",
        "\t\t\tprint('Sample Size:', sample)\n",
        "\t\t\tprint('Seed value:', seed)\n",
        "\t\t\tvalidation_accuracy = model_train(model, train_dataloader, validation_dataloader)\n",
        "\t\t\ttest_input_ids, test_attention_masks = tokenize_data(test_df)\n",
        "\t\t\ttest_dataloader = Data_Loader(test_input_ids, test_attention_masks, test_df)\n",
        "\t\t\tscores.append(model_test(model, test_dataloader))\n",
        "\t\tprint(\"The Average F1-Score of the Language \", lang, \" for the sample size \", sample,\"is:\",sum(scores)/ len(scores))\n",
        "\t\tprint(\"=\"*200)\n",
        "\t\tprint_stmts.append(\"The Average F1-Score of the Language \"+ str(lang)+ \" for the sample size \"+str(sample)+\" is : \"+str(sum(scores)/ len(scores)))\n",
        "\tfor i in print_stmts:\n",
        "\t\tprint(i,\"\\n\")\n",
        "\tprint(\"=\"*100+str(lang)+\"=\"*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXR4Uc0HY5A6"
      },
      "source": [
        "# ================================================================================================Arabic========================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 16\n",
        "# Seed value: 2018\n",
        "# /usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
        "# \tadd_(Number alpha, Tensor other)\n",
        "# Consider using one of the following signatures instead:\n",
        "# \tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
        "#   next_m.mul_(beta1).add_(1 - beta1, grad)\n",
        "# Train loss: 0.6285960078239441\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.17s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5147559642791748\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.17s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.4722505211830139\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]Validation Accuracy: 0.7839673913043478\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 16\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.805173397064209\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.17s/it]Validation Accuracy: 0.7934782608695652\n",
        "# Train loss: 0.6188700795173645\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.17s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5597631335258484\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]Validation Accuracy: 0.7880434782608695\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 16\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.7461392879486084\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.17s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.6574167609214783\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.17s/it]Validation Accuracy: 0.779891304347826\n",
        "# Train loss: 0.5073937773704529\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]Validation Accuracy: 0.7921195652173914\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 16\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.8087088465690613\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.18s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.6604413986206055\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.18s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.5117818117141724\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]Validation Accuracy: 0.7880434782608695\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 16\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.611849308013916\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.17s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.5352660417556763\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.16s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.38782766461372375\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.16s/it]Validation Accuracy: 0.779891304347826\n",
        "\n",
        "# Macro F1 Score: 0.43868153174987884\n",
        "# Accuracy score: 0.7815198618307426 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  Arabic  for the sample size  16 is: 0.4404161711495894\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 32\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.6353268623352051\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.41s/it]Validation Accuracy: 0.779891304347826\n",
        "# Train loss: 0.5921016484498978\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.41s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5422687530517578\n",
        "# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]Validation Accuracy: 0.7880434782608695\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 32\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.6266699135303497\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.40s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.5544256865978241\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.40s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.5114638358354568\n",
        "# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]Validation Accuracy: 0.7880434782608695\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 32\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.7269754409790039\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.41s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5403110086917877\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.40s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.45286594331264496\n",
        "# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]Validation Accuracy: 0.7921195652173914\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 32\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.6829738616943359\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.40s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.5652678906917572\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.40s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5043392181396484\n",
        "# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]Validation Accuracy: 0.7839673913043478\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 32\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.6909950971603394\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.41s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.5747660398483276\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.41s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.4988830238580704\n",
        "# Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]Validation Accuracy: 0.7839673913043478\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  Arabic  for the sample size  32 is: 0.44084983099951713\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 64\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.6420915797352791\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.89s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.5194012448191643\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.88s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.5137187466025352\n",
        "# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.88s/it]Validation Accuracy: 0.7880434782608695\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 64\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.5727879479527473\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.89s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.5329687222838402\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.88s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.5193874835968018\n",
        "# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.87s/it]Validation Accuracy: 0.7839673913043478\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 64\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.6105596721172333\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.88s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5475372970104218\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.87s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5497359037399292\n",
        "# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.87s/it]Validation Accuracy: 0.7880434782608695\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 64\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.584234893321991\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.88s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.5536365807056427\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.88s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.6050536558032036\n",
        "# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.87s/it]Validation Accuracy: 0.7921195652173914\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 64\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.5917189121246338\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:05,  2.87s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.527634784579277\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:05<00:02,  2.87s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.5172660946846008\n",
        "# Epoch: 100%|██████████| 3/3 [00:08<00:00,  2.87s/it]Validation Accuracy: 0.7921195652173914\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  Arabic  for the sample size  64 is: 0.44084983099951713\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 128\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.5362297296524048\n",
        "# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.86s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.5087087899446487\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.84s/it]Validation Accuracy: 0.7975543478260869\n",
        "# Train loss: 0.42960395477712154\n",
        "# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.82s/it]Validation Accuracy: 0.7894021739130435\n",
        "\n",
        "# Macro F1 Score: 0.44512784258277366\n",
        "# Accuracy score: 0.7892918825561313 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 128\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.5650436393916607\n",
        "# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.84s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5538122244179249\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.83s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.4897782802581787\n",
        "# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.83s/it]Validation Accuracy: 0.7866847826086957\n",
        "\n",
        "# Macro F1 Score: 0.6712938738239609\n",
        "# Accuracy score: 0.7849740932642487 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 128\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.5578319057822227\n",
        "# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.86s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.4551154151558876\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.85s/it]Validation Accuracy: 0.8029891304347826\n",
        "# Train loss: 0.49682338163256645\n",
        "# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.83s/it]Validation Accuracy: 0.7880434782608695\n",
        "\n",
        "# Macro F1 Score: 0.4405797101449275\n",
        "# Accuracy score: 0.7875647668393783 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 128\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.5664477348327637\n",
        "# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.83s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5019127056002617\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.83s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.523072924464941\n",
        "# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.82s/it]Validation Accuracy: 0.7921195652173914\n",
        "\n",
        "# Macro F1 Score: 0.452311738648948\n",
        "# Accuracy score: 0.7875647668393783 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 128\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.5619097538292408\n",
        "# Epoch:  33%|███▎      | 1/3 [00:03<00:07,  3.83s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.4871729947626591\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:07<00:03,  3.83s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.4266143813729286\n",
        "# Epoch: 100%|██████████| 3/3 [00:11<00:00,  3.82s/it]Validation Accuracy: 0.8152173913043478\n",
        "\n",
        "# Macro F1 Score: 0.7121728934231129\n",
        "# Accuracy score: 0.8471502590673575 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  Arabic  for the sample size  128 is: 0.5442972117247447\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 256\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.5149552151560783\n",
        "# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.74s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.5654332265257835\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.73s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5268742572516203\n",
        "# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.74s/it]Validation Accuracy: 0.7880434782608695\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 256\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.5295326877385378\n",
        "# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.75s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5236830860376358\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.74s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5614944137632847\n",
        "# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.73s/it]Validation Accuracy: 0.7880434782608695\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 256\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.5455648563802242\n",
        "# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.73s/it]Validation Accuracy: 0.7839673913043478\n",
        "# Train loss: 0.43805902637541294\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.72s/it]Validation Accuracy: 0.8342391304347826\n",
        "# Train loss: 0.3989059552550316\n",
        "# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.72s/it]Validation Accuracy: 0.842391304347826\n",
        "\n",
        "# Macro F1 Score: 0.7497429018555779\n",
        "# Accuracy score: 0.8497409326424871 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 256\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.5601061191409826\n",
        "# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.74s/it]Validation Accuracy: 0.7921195652173914\n",
        "# Train loss: 0.5226550363004208\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.73s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.5313611254096031\n",
        "# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.71s/it]Validation Accuracy: 0.7839673913043478\n",
        "\n",
        "# Macro F1 Score: 0.44084983099951713\n",
        "# Accuracy score: 0.7884283246977547 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 256\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.5431886240839958\n",
        "# Epoch:  33%|███▎      | 1/3 [00:05<00:11,  5.73s/it]Validation Accuracy: 0.7880434782608695\n",
        "# Train loss: 0.4835471361875534\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:11<00:05,  5.72s/it]Validation Accuracy: 0.7934782608695652\n",
        "# Train loss: 0.41712236404418945\n",
        "# Epoch: 100%|██████████| 3/3 [00:17<00:00,  5.72s/it]Validation Accuracy: 0.8057065217391305\n",
        "\n",
        "# Macro F1 Score: 0.7149470756660348\n",
        "# Accuracy score: 0.8031088082901554 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  Arabic  for the sample size  256 is: 0.5574478941040328\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 5064\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.3807605117418413\n",
        "# Epoch:  33%|███▎      | 1/3 [01:16<02:33, 76.68s/it]Validation Accuracy: 0.8913043478260869\n",
        "# Train loss: 0.2601510050356952\n",
        "# Epoch:  67%|██████▋   | 2/3 [02:33<01:16, 76.67s/it]Validation Accuracy: 0.8831521739130435\n",
        "# Train loss: 0.19616698427860293\n",
        "# Epoch: 100%|██████████| 3/3 [03:50<00:00, 76.71s/it]Validation Accuracy: 0.8899456521739131\n",
        "\n",
        "# Macro F1 Score: 0.8659208920794107\n",
        "# Accuracy score: 0.9214162348877375 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 5064\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.47225471240488887\n",
        "# Epoch:  33%|███▎      | 1/3 [01:17<02:34, 77.00s/it]Validation Accuracy: 0.8777173913043478\n",
        "# Train loss: 0.35469145678007263\n",
        "# Epoch:  67%|██████▋   | 2/3 [02:33<01:16, 76.97s/it]Validation Accuracy: 0.8804347826086957\n",
        "# Train loss: 0.30939961810029265\n",
        "# Epoch: 100%|██████████| 3/3 [03:50<00:00, 76.96s/it]Validation Accuracy: 0.8885869565217391\n",
        "\n",
        "# Macro F1 Score: 0.84337172015326\n",
        "# Accuracy score: 0.9024179620034543 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 5064\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.47405468369319986\n",
        "# Epoch:  33%|███▎      | 1/3 [01:17<02:34, 77.13s/it]Validation Accuracy: 0.8355978260869565\n",
        "# Train loss: 0.45086221796481013\n",
        "# Epoch:  67%|██████▋   | 2/3 [02:34<01:17, 77.06s/it]Validation Accuracy: 0.8274456521739131\n",
        "# Train loss: 0.4538565481122736\n",
        "# Epoch: 100%|██████████| 3/3 [03:51<00:00, 77.01s/it]Validation Accuracy: 0.8355978260869565\n",
        "\n",
        "# Macro F1 Score: 0.7089599760390146\n",
        "# Accuracy score: 0.8333333333333334 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 5064\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.4275432683362946\n",
        "# Epoch:  33%|███▎      | 1/3 [01:17<02:34, 77.24s/it]Validation Accuracy: 0.8682065217391305\n",
        "# Train loss: 0.28323220311185165\n",
        "# Epoch:  67%|██████▋   | 2/3 [02:34<01:17, 77.19s/it]Validation Accuracy: 0.8940217391304348\n",
        "# Train loss: 0.22640631730412647\n",
        "# Epoch: 100%|██████████| 3/3 [03:51<00:00, 77.13s/it]Validation Accuracy: 0.8980978260869565\n",
        "\n",
        "# Macro F1 Score: 0.923288397204465\n",
        "# Accuracy score: 0.9516407599309153 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: Arabic\n",
        "# Sample Size: 5064\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.42129089382450663\n",
        "# Epoch:  33%|███▎      | 1/3 [01:16<02:33, 76.87s/it]Validation Accuracy: 0.8654891304347826\n",
        "# Train loss: 0.2921814020335298\n",
        "# Epoch:  67%|██████▋   | 2/3 [02:34<01:16, 76.96s/it]Validation Accuracy: 0.8790760869565217\n",
        "# Train loss: 0.21534004936447185\n",
        "# Epoch: 100%|██████████| 3/3 [03:51<00:00, 77.11s/it]Validation Accuracy: 0.8899456521739131\n",
        "\n",
        "# Macro F1 Score: 0.921841252699784\n",
        "# Accuracy score: 0.9499136442141624 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  Arabic  for the sample size  5064 is: 0.852676447635187\n",
        "# ========================================================================================================================================================================================================\n",
        "# The Average F1-Score of the Language Arabic for the sample size 16 is : 0.4404161711495894 \n",
        "\n",
        "# The Average F1-Score of the Language Arabic for the sample size 32 is : 0.44084983099951713 \n",
        "\n",
        "# The Average F1-Score of the Language Arabic for the sample size 64 is : 0.44084983099951713 \n",
        "\n",
        "# The Average F1-Score of the Language Arabic for the sample size 128 is : 0.5442972117247447 \n",
        "\n",
        "# The Average F1-Score of the Language Arabic for the sample size 256 is : 0.5574478941040328 \n",
        "\n",
        "# The Average F1-Score of the Language Arabic for the sample size 5064 is : 0.852676447635187 \n",
        "# =============================================================================================French===========================================================================================================\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 16\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.7142896056175232\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.48it/s]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6549753546714783\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.5957129597663879\n",
        "# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.51it/s]Validation Accuracy: 0.6729166666666667\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 16\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.7049331068992615\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6364553570747375\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.54it/s]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6657148599624634\n",
        "# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]Validation Accuracy: 0.6680555555555555\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 16\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.6984119415283203\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.54it/s]Validation Accuracy: 0.6875\n",
        "# Train loss: 0.6571838855743408\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.54it/s]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.595601499080658\n",
        "# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.54it/s]Validation Accuracy: 0.6631944444444444\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 16\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.7203541398048401\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.49it/s]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6451766490936279\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.5743436217308044\n",
        "# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.52it/s]Validation Accuracy: 0.6777777777777778\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 16\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.6835259199142456\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.53it/s]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6288159489631653\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.53it/s]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.576382040977478\n",
        "# Epoch: 100%|██████████| 3/3 [00:01<00:00,  1.53it/s]Validation Accuracy: 0.6631944444444444\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  French  for the sample size  16 is: 0.4019607843137255\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 32\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.6688138842582703\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.12it/s]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.606219619512558\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.12it/s]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.5355419516563416\n",
        "# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]Validation Accuracy: 0.6729166666666667\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 32\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.6715655028820038\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.10it/s]Validation Accuracy: 0.6875\n",
        "# Train loss: 0.6776262819766998\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.11it/s]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6306291222572327\n",
        "# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.11it/s]Validation Accuracy: 0.6777777777777778\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 32\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.7045533359050751\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.12it/s]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6735416352748871\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.12it/s]Validation Accuracy: 0.6631944444444444\n",
        "# Train loss: 0.5860183238983154\n",
        "# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]Validation Accuracy: 0.6777777777777778\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 32\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.6769523918628693\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.13it/s]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6013891100883484\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.13it/s]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.5441319942474365\n",
        "# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]Validation Accuracy: 0.6680555555555555\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 32\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.7622263729572296\n",
        "# Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.11it/s]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6264231503009796\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.11it/s]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.5352326035499573\n",
        "# Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.12it/s]Validation Accuracy: 0.6631944444444444\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  French  for the sample size  32 is: 0.4019607843137255\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 64\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.6489704847335815\n",
        "# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.37s/it]Validation Accuracy: 0.6631944444444444\n",
        "# Train loss: 0.6532268598675728\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6288694739341736\n",
        "# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]Validation Accuracy: 0.6729166666666667\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 64\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.6748755872249603\n",
        "# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.36s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.62314572930336\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6254115998744965\n",
        "# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]Validation Accuracy: 0.6777777777777778\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 64\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.6513359248638153\n",
        "# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.40s/it]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6510126143693924\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.39s/it]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6253663003444672\n",
        "# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]Validation Accuracy: 0.6777777777777778\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 64\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.6683451682329178\n",
        "# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.36s/it]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6408082991838455\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]Validation Accuracy: 0.6826388888888889\n",
        "# Train loss: 0.5378864482045174\n",
        "# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]Validation Accuracy: 0.6506944444444445\n",
        "\n",
        "# Macro F1 Score: 0.4391796322489392\n",
        "# Accuracy score: 0.680327868852459 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 64\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.6418927609920502\n",
        "# Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.37s/it]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6280799806118011\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]Validation Accuracy: 0.6819444444444445\n",
        "# Train loss: 0.46665120869874954\n",
        "# Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.36s/it]Validation Accuracy: 0.5541666666666667\n",
        "\n",
        "# Macro F1 Score: 0.5959368331199317\n",
        "# Accuracy score: 0.6024590163934426 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  French  for the sample size  64 is: 0.44819976366200953\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 128\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.65238968282938\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.31s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6337575688958168\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.31s/it]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6280350871384144\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.31s/it]Validation Accuracy: 0.6729166666666667\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 128\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.6491170227527618\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.30s/it]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6507724896073341\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.30s/it]Validation Accuracy: 0.6631944444444444\n",
        "# Train loss: 0.6340348869562149\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.30s/it]Validation Accuracy: 0.6777777777777778\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 128\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.6820387914776802\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.33s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6307911276817322\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.33s/it]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6436115093529224\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.32s/it]Validation Accuracy: 0.6729166666666667\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 128\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.6609269604086876\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.31s/it]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6502581536769867\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.31s/it]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6352989301085472\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.31s/it]Validation Accuracy: 0.6631944444444444\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 128\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.6661690846085548\n",
        "# Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.30s/it]Validation Accuracy: 0.6826388888888889\n",
        "# Train loss: 0.653712909668684\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.30s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6119441613554955\n",
        "# Epoch: 100%|██████████| 3/3 [00:06<00:00,  2.30s/it]Validation Accuracy: 0.6826388888888889\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  French  for the sample size  128 is: 0.4019607843137255\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 256\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.6596672479063272\n",
        "# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.22s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6491341702640057\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.21s/it]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6628831457346678\n",
        "# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.20s/it]Validation Accuracy: 0.6826388888888889\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 256\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.6479477919638157\n",
        "# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.19s/it]Validation Accuracy: 0.6826388888888889\n",
        "# Train loss: 0.6518803387880325\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.19s/it]Validation Accuracy: 0.6826388888888889\n",
        "# Train loss: 0.6390225514769554\n",
        "# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.19s/it]Validation Accuracy: 0.6826388888888889\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 256\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.6542846225202084\n",
        "# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.22s/it]Validation Accuracy: 0.6826388888888889\n",
        "# Train loss: 0.6369277238845825\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.21s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6259830463677645\n",
        "# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.22s/it]Validation Accuracy: 0.6777777777777778\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 256\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.6535199545323849\n",
        "# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.20s/it]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6606243625283241\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.19s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6693457141518593\n",
        "# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.20s/it]Validation Accuracy: 0.6826388888888889\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 256\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.6771242804825306\n",
        "# Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.21s/it]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6336890235543251\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.20s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6499033980071545\n",
        "# Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.21s/it]Validation Accuracy: 0.6729166666666667\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  French  for the sample size  256 is: 0.4019607843137255\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 1067\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.6314995351122387\n",
        "# Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.20s/it]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6115920014345824\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.19s/it]Validation Accuracy: 0.6416666666666667\n",
        "# Train loss: 0.5709722771573422\n",
        "# Epoch: 100%|██████████| 3/3 [00:48<00:00, 16.19s/it]Validation Accuracy: 0.6770833333333333\n",
        "\n",
        "# Macro F1 Score: 0.6000504350018914\n",
        "# Accuracy score: 0.7336065573770492 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 1067\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.6434728467642371\n",
        "# Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.16s/it]Validation Accuracy: 0.6631944444444444\n",
        "# Train loss: 0.6363175524704492\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.17s/it]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6373279508370072\n",
        "# Epoch: 100%|██████████| 3/3 [00:48<00:00, 16.18s/it]Validation Accuracy: 0.6777777777777778\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 1067\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.642752572671691\n",
        "# Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.25s/it]Validation Accuracy: 0.6729166666666667\n",
        "# Train loss: 0.6444720038727149\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.22s/it]Validation Accuracy: 0.6777777777777778\n",
        "# Train loss: 0.6391191295723417\n",
        "# Epoch: 100%|██████████| 3/3 [00:48<00:00, 16.20s/it]Validation Accuracy: 0.6777777777777778\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 1067\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.6484330069662919\n",
        "# Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.27s/it]Validation Accuracy: 0.6826388888888889\n",
        "# Train loss: 0.6467400971633285\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.24s/it]Validation Accuracy: 0.6680555555555555\n",
        "# Train loss: 0.6357286229952058\n",
        "# Epoch: 100%|██████████| 3/3 [00:48<00:00, 16.23s/it]Validation Accuracy: 0.6631944444444444\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: French\n",
        "# Sample Size: 1067\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.649295850921033\n",
        "# Epoch:  33%|███▎      | 1/3 [00:16<00:32, 16.21s/it]Validation Accuracy: 0.6826388888888889\n",
        "# Train loss: 0.648297337008946\n",
        "# Epoch:  67%|██████▋   | 2/3 [00:32<00:16, 16.19s/it]Validation Accuracy: 0.6583333333333333\n",
        "# Train loss: 0.6351088134210501\n",
        "# Epoch: 100%|██████████| 3/3 [00:48<00:00, 16.18s/it]Validation Accuracy: 0.6680555555555555\n",
        "\n",
        "# Macro F1 Score: 0.40196078431372545\n",
        "# Accuracy score: 0.6721311475409836 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  French  for the sample size  1067 is: 0.4415787144513586\n",
        "# ========================================================================================================================================================================================================\n",
        "# The Average F1-Score of the Language French for the sample size 16 is : 0.4201313506375065 \n",
        "\n",
        "# The Average F1-Score of the Language French for the sample size 32 is : 0.4144100855098297 \n",
        "\n",
        "# The Average F1-Score of the Language French for the sample size 64 is : 0.44819976366200953 \n",
        "\n",
        "# The Average F1-Score of the Language French for the sample size 128 is : 0.4065285520148653 \n",
        "\n",
        "# The Average F1-Score of the Language French for the sample size 256 is : 0.4348942321008883 \n",
        "\n",
        "# The Average F1-Score of the Language French for the sample size 1067 is : 0.5285378393334661 \n",
        "\n",
        "# =======================================================================================================English=================================================================================================\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 16\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.7012133598327637\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.10s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.6003368496894836\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.12s/it]Validation Accuracy: 0.8069698808473081\n",
        "# Train loss: 0.4720257520675659\n",
        "# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.15s/it]Validation Accuracy: 0.8070043578993822\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 16\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.6294952630996704\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.16s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.5633472204208374\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.18s/it]Validation Accuracy: 0.8069009267431597\n",
        "# Train loss: 0.5078692436218262\n",
        "# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.19s/it]Validation Accuracy: 0.8069698808473081\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 16\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.7258316874504089\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.15s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.6431592702865601\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.17s/it]Validation Accuracy: 0.8069009267431597\n",
        "# Train loss: 0.5583165287971497\n",
        "# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.18s/it]Validation Accuracy: 0.8070043578993822\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 16\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.6851200461387634\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.15s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.5778971314430237\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.16s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.49538373947143555\n",
        "# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.18s/it]Validation Accuracy: 0.8069009267431597\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 16\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.6158103942871094\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.16s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.5535745024681091\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.18s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.5013738870620728\n",
        "# Epoch: 100%|██████████| 3/3 [01:45<00:00, 35.19s/it]Validation Accuracy: 0.8069354037952339\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  English  for the sample size  16 is: 0.4465907301453992\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 32\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.5629978328943253\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.37s/it]Validation Accuracy: 0.806811286407767\n",
        "# Train loss: 0.41269566118717194\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.39s/it]Validation Accuracy: 0.8062872352162401\n",
        "# Train loss: 0.45645563304424286\n",
        "# Epoch: 100%|██████████| 3/3 [01:46<00:00, 35.42s/it]Validation Accuracy: 0.8046254413062666\n",
        "\n",
        "# Macro F1 Score: 0.44982134536948326\n",
        "# Accuracy score: 0.8057953144266338 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 32\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.6188765466213226\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.38s/it]Validation Accuracy: 0.8069698808473081\n",
        "# Train loss: 0.5668856203556061\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.39s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.45990003645420074\n",
        "# Epoch: 100%|██████████| 3/3 [01:46<00:00, 35.41s/it]Validation Accuracy: 0.8069354037952339\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 32\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.7718203663825989\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.44s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.5359033197164536\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.44s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.48729319870471954\n",
        "# Epoch: 100%|██████████| 3/3 [01:46<00:00, 35.44s/it]Validation Accuracy: 0.8070388349514563\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 32\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.564655214548111\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.48s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.4464970678091049\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.48s/it]Validation Accuracy: 0.8069698808473081\n",
        "# Train loss: 0.4259660542011261\n",
        "# Epoch: 100%|██████████| 3/3 [01:46<00:00, 35.49s/it]Validation Accuracy: 0.8069009267431597\n",
        "\n",
        "# Macro F1 Score: 0.4468335060769663\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 32\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.6386640071868896\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:10, 35.43s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.549001008272171\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:10<00:35, 35.44s/it]Validation Accuracy: 0.8068319726390115\n",
        "# Train loss: 0.44959187507629395\n",
        "# Epoch: 100%|██████████| 3/3 [01:46<00:00, 35.44s/it]Validation Accuracy: 0.8070388349514563\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  English  for the sample size  32 is: 0.4472854083765294\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 64\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.5919364392757416\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.90s/it]Validation Accuracy: 0.8069698808473081\n",
        "# Train loss: 0.49837175011634827\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.89s/it]Validation Accuracy: 0.8068319726390115\n",
        "# Train loss: 0.3761015608906746\n",
        "# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.90s/it]Validation Accuracy: 0.7514618270079436\n",
        "\n",
        "# Macro F1 Score: 0.6019333562659456\n",
        "# Accuracy score: 0.7507350848904486 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 64\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.5248944461345673\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.84s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.4691205471754074\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.81s/it]Validation Accuracy: 0.28078800750220656\n",
        "# Train loss: 0.49470213800668716\n",
        "# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.79s/it]Validation Accuracy: 0.8070043578993822\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 64\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.5320430919528008\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.88s/it]Validation Accuracy: 0.8069698808473081\n",
        "# Train loss: 0.4908973053097725\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.90s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.4784261956810951\n",
        "# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.93s/it]Validation Accuracy: 0.8069698808473081\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 64\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.49988001585006714\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.91s/it]Validation Accuracy: 0.8069698808473081\n",
        "# Train loss: 0.5036658197641373\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.91s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.49153272807598114\n",
        "# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.91s/it]Validation Accuracy: 0.8069698808473081\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 64\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.554820604622364\n",
        "# Epoch:  33%|███▎      | 1/3 [00:35<01:11, 35.88s/it]Validation Accuracy: 0.8069009267431597\n",
        "# Train loss: 0.4569332152605057\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:11<00:35, 35.89s/it]Validation Accuracy: 0.8069698808473081\n",
        "# Train loss: 0.48466112464666367\n",
        "# Epoch: 100%|██████████| 3/3 [01:47<00:00, 35.91s/it]Validation Accuracy: 0.8070043578993822\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  English  for the sample size  64 is: 0.47765925536950854\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 128\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.5251889191567898\n",
        "# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.82s/it]Validation Accuracy: 0.8066733781994704\n",
        "# Train loss: 0.5091251321136951\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.84s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.49760130420327187\n",
        "# Epoch: 100%|██████████| 3/3 [01:50<00:00, 36.85s/it]Validation Accuracy: 0.8069354037952339\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 128\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.546096283942461\n",
        "# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.89s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.5061495248228312\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.89s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.5227790139615536\n",
        "# Epoch: 100%|██████████| 3/3 [01:50<00:00, 36.88s/it]Validation Accuracy: 0.8070388349514563\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 128\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.606844250112772\n",
        "# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.81s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.49054910242557526\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.81s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.49353083968162537\n",
        "# Epoch: 100%|██████████| 3/3 [01:50<00:00, 36.85s/it]Validation Accuracy: 0.8069009267431597\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 128\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.5471498891711235\n",
        "# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.93s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.46142368391156197\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.94s/it]Validation Accuracy: 0.719067188879082\n",
        "# Train loss: 0.33735150285065174\n",
        "# Epoch: 100%|██████████| 3/3 [01:50<00:00, 36.95s/it]Validation Accuracy: 0.8015914607237422\n",
        "\n",
        "# Macro F1 Score: 0.4990581769085374\n",
        "# Accuracy score: 0.802902399696481 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 128\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.5545864291489124\n",
        "# Epoch:  33%|███▎      | 1/3 [00:36<01:13, 36.90s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.4880603291094303\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:13<00:36, 36.91s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.41585424169898033\n",
        "# Epoch: 100%|██████████| 3/3 [01:50<00:00, 36.92s/it]Validation Accuracy: 0.7631288614298324\n",
        "\n",
        "# Macro F1 Score: 0.5885148423118556\n",
        "# Accuracy score: 0.7589870055961301 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  English  for the sample size  128 is: 0.4854690419313181\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 256\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.5465956330299377\n",
        "# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.81s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.49011561647057533\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.82s/it]Validation Accuracy: 0.8070043578993822\n",
        "# Train loss: 0.49254709761589766\n",
        "# Epoch: 100%|██████████| 3/3 [01:56<00:00, 38.84s/it]Validation Accuracy: 0.8069698808473081\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 256\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.594136593863368\n",
        "# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.62s/it]Validation Accuracy: 0.8068664496910856\n",
        "# Train loss: 0.518953531049192\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.62s/it]Validation Accuracy: 0.8068664496910856\n",
        "# Train loss: 0.5037310030311346\n",
        "# Epoch: 100%|██████████| 3/3 [01:55<00:00, 38.62s/it]Validation Accuracy: 0.8069354037952339\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 256\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.5425154725089669\n",
        "# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.68s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.4992446955293417\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.67s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.4972736928611994\n",
        "# Epoch: 100%|██████████| 3/3 [01:55<00:00, 38.63s/it]Validation Accuracy: 0.8069698808473081\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 256\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.517131520435214\n",
        "# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.77s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.49811363220214844\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.78s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.49926822632551193\n",
        "# Epoch: 100%|██████████| 3/3 [01:56<00:00, 38.80s/it]Validation Accuracy: 0.8069009267431597\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 256\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.5336637105792761\n",
        "# Epoch:  33%|███▎      | 1/3 [00:38<01:17, 38.83s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.5113212177529931\n",
        "# Epoch:  67%|██████▋   | 2/3 [01:17<00:38, 38.82s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.4976142346858978\n",
        "# Epoch: 100%|██████████| 3/3 [01:56<00:00, 38.81s/it]Validation Accuracy: 0.8069354037952339\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  English  for the sample size  256 is: 0.4465907301453992\n",
        "# ========================================================================================================================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 92247\n",
        "# Seed value: 2018\n",
        "# Train loss: 0.4621616079757249\n",
        "# Epoch:  33%|███▎      | 1/3 [23:17<46:34, 1397.35s/it]Validation Accuracy: 0.827442354368932\n",
        "# Train loss: 0.44153438023046987\n",
        "# Epoch:  67%|██████▋   | 2/3 [46:33<23:17, 1397.09s/it]Validation Accuracy: 0.8202021734333628\n",
        "# Train loss: 0.4460624627771578\n",
        "# Epoch: 100%|██████████| 3/3 [1:09:48<00:00, 1396.24s/it]Validation Accuracy: 0.8069009267431597\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 92247\n",
        "# Seed value: 2019\n",
        "# Train loss: 0.43749778108762405\n",
        "# Epoch:  33%|███▎      | 1/3 [23:11<46:22, 1391.48s/it]Validation Accuracy: 0.8191402802294793\n",
        "# Train loss: 0.4834461185488071\n",
        "# Epoch:  67%|██████▋   | 2/3 [46:20<23:10, 1390.81s/it]Validation Accuracy: 0.8258495145631068\n",
        "# Train loss: 0.4719561161515389\n",
        "# Epoch: 100%|██████████| 3/3 [1:09:30<00:00, 1390.08s/it]Validation Accuracy: 0.8363167475728155\n",
        "\n",
        "# Macro F1 Score: 0.6762370852033299\n",
        "# Accuracy score: 0.8356729583609979 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 92247\n",
        "# Seed value: 2020\n",
        "# Train loss: 0.3441592636710389\n",
        "# Epoch:  33%|███▎      | 1/3 [23:11<46:23, 1391.97s/it]Validation Accuracy: 0.8605954876434246\n",
        "# Train loss: 0.29897861119955416\n",
        "# Epoch:  67%|██████▋   | 2/3 [46:19<23:10, 1390.49s/it]Validation Accuracy: 0.8639673433362753\n",
        "# Train loss: 0.28014618978343653\n",
        "# Epoch: 100%|██████████| 3/3 [1:09:27<00:00, 1389.33s/it]Validation Accuracy: 0.8654843336275375\n",
        "\n",
        "# Macro F1 Score: 0.7986555259115466\n",
        "# Accuracy score: 0.8903537892440482 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 92247\n",
        "# Seed value: 2021\n",
        "# Train loss: 0.47905288315970906\n",
        "# Epoch:  33%|███▎      | 1/3 [23:00<46:01, 1380.65s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.490492340803994\n",
        "# Epoch:  67%|██████▋   | 2/3 [46:00<23:00, 1380.47s/it]Validation Accuracy: 0.8070388349514563\n",
        "# Train loss: 0.4901451638257218\n",
        "# Epoch: 100%|██████████| 3/3 [1:08:58<00:00, 1379.43s/it]Validation Accuracy: 0.8069698808473081\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# t_total value of -1 results in schedule not being applied\n",
        "# Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (552 > 512). Running this sequence through BERT will result in indexing errors\n",
        "# Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\n",
        "# Model Summary:\n",
        "# Language: English\n",
        "# Sample Size: 92247\n",
        "# Seed value: 2022\n",
        "# Train loss: 0.49252669572018726\n",
        "# Epoch:  33%|███▎      | 1/3 [23:03<46:06, 1383.13s/it]Validation Accuracy: 0.8069354037952339\n",
        "# Train loss: 0.49225411624326254\n",
        "# Epoch:  67%|██████▋   | 2/3 [46:00<23:01, 1381.48s/it]Validation Accuracy: 0.8069009267431597\n",
        "# Train loss: 0.49193255676708\n",
        "# Epoch: 100%|██████████| 3/3 [1:08:51<00:00, 1377.17s/it]Validation Accuracy: 0.8069698808473081\n",
        "\n",
        "# Macro F1 Score: 0.4465907301453992\n",
        "# Accuracy score: 0.80698093521768 \n",
        "\n",
        "# ====================================================================================================\n",
        "# The Average F1-Score of the Language  English  for the sample size  92247 is: 0.5629329603102148\n",
        "# ========================================================================================================================================================================================================\n",
        "\n",
        "# The Average F1-Score of the Language English for the sample size 16 is : 0.4465907301453992 \n",
        "\n",
        "# The Average F1-Score of the Language English for the sample size 32 is : 0.4472854083765294 \n",
        "\n",
        "# The Average F1-Score of the Language English for the sample size 64 is : 0.47765925536950854 \n",
        "\n",
        "# The Average F1-Score of the Language English for the sample size 128 is : 0.4854690419313181 \n",
        "\n",
        "# The Average F1-Score of the Language English for the sample size 256 is : 0.4465907301453992 \n",
        "\n",
        "# The Average F1-Score of the Language English for the sample size 92247 is : 0.5629329603102148 \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}