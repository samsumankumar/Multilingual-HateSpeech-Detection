{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Adapter_mBert_monolingual.ipynb","provenance":[{"file_id":"1iQCzVh26L_9bXsnBzOo8uqiu3yn67KI4","timestamp":1606778720661}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mg0CVDPANAQu","executionInfo":{"status":"ok","timestamp":1607024697852,"user_tz":300,"elapsed":15392,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}},"outputId":"03850325-9994-423b-aa9a-bbe043a8a112"},"source":["#!pip install git+https://github.com/adapter-hub/adapter-transformers.git\n","!git clone https://github.com/huggingface/transformers\n","!pip install emoji\n","!pip install -U adapter-transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 144, done.\u001b[K\n","remote: Counting objects: 100% (144/144), done.\u001b[K\n","remote: Compressing objects: 100% (104/104), done.\u001b[K\n","remote: Total 54554 (delta 60), reused 81 (delta 18), pack-reused 54410\u001b[K\n","Receiving objects: 100% (54554/54554), 40.73 MiB | 30.47 MiB/s, done.\n","Resolving deltas: 100% (38115/38115), done.\n","Collecting emoji\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-0.6.0-cp36-none-any.whl size=49716 sha256=87f2b5a6d6ee7f416551206aee4f8babbcd3c0da9b279b7bd4b894352e34af97\n","  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-0.6.0\n","Collecting adapter-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/44/1370c187aba1349d56d6813ec4de54644d15e154983050f4923ce5455069/adapter_transformers-1.1.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 9.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from adapter-transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from adapter-transformers) (0.8)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from adapter-transformers) (2.23.0)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from adapter-transformers) (20.4)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from adapter-transformers) (3.0.12)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 31.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from adapter-transformers) (4.41.1)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 37.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from adapter-transformers) (3.12.4)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from adapter-transformers) (1.18.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 66.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->adapter-transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->adapter-transformers) (2020.11.8)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->adapter-transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->adapter-transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->adapter-transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->adapter-transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->adapter-transformers) (50.3.2)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->adapter-transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->adapter-transformers) (0.17.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=09c594981e6da4794fce6faf02a934aa7ef58c759a8787dab4b9450a4e3a4274\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, adapter-transformers\n","Successfully installed adapter-transformers-1.1.0 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"OQm3ppBnNCSf","executionInfo":{"status":"ok","timestamp":1607024847251,"user_tz":300,"elapsed":336,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}},"outputId":"48f3d41e-5fbe-498e-e717-95560a5941ff"},"source":["import numpy as np\n","import torch\n","from transformers import AutoTokenizer, EvalPrediction, BertTokenizerFast, AdapterType, AutoModelWithHeads\n","from transformers import Trainer,TrainingArguments, set_seed\n","import warnings\n","\n","warnings.simplefilter(\"ignore\", UserWarning)\n","warnings.simplefilter(\"ignore\", FutureWarning)\n","warnings.simplefilter(\"ignore\", DeprecationWarning)\n","\n","import tensorflow as tf\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, Dataset\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","from transformers import (\n","    Trainer,\n","    TrainingArguments,\n","    )\n","import os\n","import re\n","import emoji\n","import random\n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk import word_tokenize, pos_tag\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import sent_tokenize, TweetTokenizer\n","from nltk.corpus import wordnet, stopwords\n","\n","# specify GPU device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"ywOpu_-6NFcP"},"source":["def preprocess(df):\n","    \n","    #removes URL\n","    pattern = r'https.?://[^\\s]+[\\s]?'\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\"\", regex=True)\n","    \n","    #removes usernames/mentions\n","    pattern = r'@[^\\s]+'\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\"\", regex=True)\n","    \n","    #removes emoji and smiley\n","    pattern = re.compile(\"[\"\n","                         u\"\\U0001F600-\\U0001F64F\"\n","                         u\"\\U0001F300-\\U0001F5FF\"\n","                         u\"\\U0001F680-\\U0001F6FF\"\n","                         u\"\\U0001F1E0-\\U0001F1FF\"\n","                         u\"\\U00002500-\\U00002BEF\"\n","                         u\"\\U00002702-\\U000027B0\"\n","                         u\"\\U00002702-\\U000027B0\"\n","                         u\"\\U000024C2-\\U0001F251\"\n","                         u\"\\U0001f926-\\U0001f937\"\n","                         u\"\\U00010000-\\U0010ffff\"\n","                         u\"\\u2640-\\u2642\"\n","                         u\"\\u2600-\\u2B55\"\n","                         u\"\\u200d\"\n","                         u\"\\u23cf\"\n","                         u\"\\u23e9\"\n","                         u\"\\u231a\"\n","                         u\"\\ufe0f\"\n","                         u\"\\u3030\"\n","                         \"]+\", flags=re.UNICODE)\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\"\", regex=True)\n","    \n","    #removes numbers\n","    pattern = r'\\d+'\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\"\", regex=True)\n","    \n","    #removes punctuation\n","    pattern = r\"[^\\w\\s]\"\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\" \", regex=True)\n","\n","    #removes stop words\n","    stop_words = stopwords.words(\"english\")    \n","    remove_stop_words = lambda row: \" \".join([token for token in row.split(\" \")\n","                                              if token not in stop_words])\n","    df[\"tweet\"] = df[\"tweet\"].apply(remove_stop_words)\n","    \n","    #removes extra spaces\n","    pattern = r\"[\\s]+\"\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\" \", regex=True)\n","    \n","    return(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQT-aCAxNIov"},"source":["def train_validate_test_split(df,seed= 2018, train_percent=.8, validate_percent=.125):\n","  train_tweet, test_tweet, train_label, test_label  = train_test_split(df.tweet.tolist(), df.label.tolist(), train_size=train_percent, stratify=df['label'])\n","  train_tweet, validate_tweet, train_label, validate_label = train_test_split(train_tweet, train_label, test_size=validate_percent, stratify=train_label)\n","  return train_tweet, validate_tweet, test_tweet, train_label, validate_label, test_label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zfLg8FjMNL93"},"source":["class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3cceXKx5NWFh"},"source":["def model_initialize(model_name, num_labels = 2):\n","  model = AutoModelWithHeads.from_pretrained(model_name)\n","  model.add_adapter(\"sst-2\", AdapterType.text_task)\n","  model.add_classification_head(\"sst-2\", num_labels=num_labels)\n","  model.train_adapter([\"sst-2\"])\n","  model.set_active_adapters([[\"sst-2\"]])\n","\n","  # we freeze the model weights which in turn they wont be updated\n","  for param in model.base_model.parameters():\n","      param.requires_grad = False\n","  \n","  training_args = TrainingArguments(\n","    logging_steps=50,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    evaluation_strategy='epoch',\n","    output_dir=\"./\",\n","    overwrite_output_dir=True,\n","    learning_rate=1e-4,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    do_train=True,\n","    do_eval=True,\n","    do_predict=True,\n","    num_train_epochs=5)\n","  \n","  set_seed(training_args.seed)\n","  return model, training_args"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3z93TccLNhlA"},"source":["def Train_model(model, training_args, train_dataset, val_dataset, test_dataset, test_label):\n","  trainer = Trainer(\n","      model=model,\n","      args=training_args,\n","      train_dataset = train_dataset,\n","      eval_dataset = val_dataset)\n","  \n","  trainer.train()\n","  pred = trainer.predict(test_dataset)\n","  pred = np.argmax(pred[0],axis=1)\n","  print(\"The Weighted F1- Score is: \", f1_score(np.array(test_label), pred, average = 'weighted'))\n","  print(\"The Macro F1- Score is: \", f1_score(np.array(test_label), pred, average = 'macro'))\n","  print(\"Accuracy is: \", accuracy_score(np.array(test_label), pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ARPUew0JNils","executionInfo":{"status":"ok","timestamp":1607027135111,"user_tz":300,"elapsed":2286539,"user":{"displayName":"suman kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GicqVxGKhLDa6B_sPiIJNdXw6DBlngT2WcJJDwkwg=s64","userId":"06576966373551741897"}},"outputId":"4e86da2e-97c3-49c8-d0b2-47771a029ba9"},"source":["directory = \"./\"\n","languages = ['French', 'Arabic', 'English']\n","model_name = \"bert-base-multilingual-uncased\"\n","tokenizer = BertTokenizerFast.from_pretrained(model_name)\n","for lang in languages:\n","\tdf = pd.read_csv(os.path.join(directory, lang+'.csv'))\n","\tdf = preprocess(df)\n","\ttrain_tweet, validate_tweet, test_tweet, train_label, validate_label, test_label = train_validate_test_split(df,seed= 2018, train_percent=.8, validate_percent=.125)\n"," \n","\ttrain_encodings = tokenizer(train_tweet, truncation=True, padding='max_length', max_length=128)\n","\tval_encodings = tokenizer(validate_tweet, truncation=True, padding='max_length', max_length=128)\n","\ttest_encodings = tokenizer(test_tweet, truncation=True, padding='max_length', max_length=128)\n","\ttrain_dataset = Dataset(train_encodings, train_label)\n","\tval_dataset = Dataset(val_encodings, validate_label)\n","\ttest_dataset = Dataset(test_encodings, test_label)\n"," \n","\tmodel, training_args = model_initialize(model_name, num_labels = 2)\n","\tTrain_model(model, training_args, train_dataset, val_dataset, test_dataset, test_label)\n","\t# model.save_adapter(os.path.join(\"./\", lang), \"sst-2\", with_head=True)\n","\tprint(\"=\"*200)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [270/270 00:22, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.691411</td>\n","      <td>0.646310</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.649923</td>\n","      <td>0.631674</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.632139</td>\n","      <td>0.629837</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.625068</td>\n","      <td>0.624890</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.642587</td>\n","      <td>0.635239</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [16/16 00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["The Weighted F1- Score is:  0.5403407264545163\n","The Macro F1- Score is:  0.40196078431372545\n","Accuracy is:  0.6721311475409836\n","========================================================================================================================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1270' max='1270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1270/1270 01:50, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.494047</td>\n","      <td>0.510176</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.489158</td>\n","      <td>0.491935</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.466574</td>\n","      <td>0.480244</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.472885</td>\n","      <td>0.472351</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.468894</td>\n","      <td>0.474924</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [73/73 00:04]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["The Weighted F1- Score is:  0.6951569873964752\n","The Macro F1- Score is:  0.44084983099951713\n","Accuracy is:  0.7884283246977547\n","========================================================================================================================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='23065' max='23065' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [23065/23065 33:48, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.415525</td>\n","      <td>0.431277</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.418477</td>\n","      <td>0.412855</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.404766</td>\n","      <td>0.405521</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.425957</td>\n","      <td>0.404801</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.349258</td>\n","      <td>0.405263</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1318' max='1318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1318/1318 01:26]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["The Weighted F1- Score is:  0.7660603286094521\n","The Macro F1- Score is:  0.5566253423076104\n","Accuracy is:  0.8190742672863511\n","========================================================================================================================================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"M4YWRHpTYdcX"},"source":["# model.load_head(\"./Arabic\")\n","# model.load_head(\"./French\")\n","# model.load_head(\"./English\")"],"execution_count":null,"outputs":[]}]}