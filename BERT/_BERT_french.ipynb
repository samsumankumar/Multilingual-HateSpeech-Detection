{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" BERT_french.ipynb","provenance":[{"file_id":"1UJPUgsgtZnh66_9KPHyaxdlL6NSfhWZQ","timestamp":1606165712268}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyM2gw1vqStiVhjTl2sKZ79R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fvy2c887aK4y","executionInfo":{"status":"ok","timestamp":1607218441280,"user_tz":300,"elapsed":1123,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}},"outputId":"59d551b6-7ae2-4804-dd29-73e6d60ec928"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nU58fyX3aWYT","executionInfo":{"status":"ok","timestamp":1607218444074,"user_tz":300,"elapsed":3905,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}},"outputId":"5d126291-4ab1-46c2-f892-18bdfbc7dcdb"},"source":["!pip install transformers"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IGpvl8-iBLSi","executionInfo":{"status":"ok","timestamp":1607218447022,"user_tz":300,"elapsed":6846,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}},"outputId":"097a28cc-549d-4745-c154-dc15db4d4a70"},"source":["!pip install emoji"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"4KyBcSEbadZQ","executionInfo":{"status":"ok","timestamp":1607218447793,"user_tz":300,"elapsed":7609,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}},"outputId":"c5c508b9-ca29-4711-ac21-256a2a00d5f9"},"source":["import tensorflow as tf\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","#from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertAdam, BertForSequenceClassification\n","from transformers import BertForSequenceClassification, BertTokenizer\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import os\n","import re\n","import emoji\n","import random\n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk import word_tokenize, pos_tag\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import sent_tokenize, TweetTokenizer\n","from nltk.corpus import wordnet, stopwords\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import f1_score, accuracy_score\n","from statistics import mode\n","\n","\n","# specify GPU device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"2_52J_OQ2dA6","executionInfo":{"status":"ok","timestamp":1607218447794,"user_tz":300,"elapsed":7602,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}}},"source":["def preprocess(df):\n","    \n","    #removes URL\n","    pattern = r'https.?://[^\\s]+[\\s]?'\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\"\", regex=True)\n","    \n","    #removes usernames/mentions\n","    pattern = r'@[^\\s]+'\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\"\", regex=True)\n","    \n","    #removes emoji and smiley\n","    pattern = re.compile(\"[\"\n","                         u\"\\U0001F600-\\U0001F64F\"\n","                         u\"\\U0001F300-\\U0001F5FF\"\n","                         u\"\\U0001F680-\\U0001F6FF\"\n","                         u\"\\U0001F1E0-\\U0001F1FF\"\n","                         u\"\\U00002500-\\U00002BEF\"\n","                         u\"\\U00002702-\\U000027B0\"\n","                         u\"\\U00002702-\\U000027B0\"\n","                         u\"\\U000024C2-\\U0001F251\"\n","                         u\"\\U0001f926-\\U0001f937\"\n","                         u\"\\U00010000-\\U0010ffff\"\n","                         u\"\\u2640-\\u2642\"\n","                         u\"\\u2600-\\u2B55\"\n","                         u\"\\u200d\"\n","                         u\"\\u23cf\"\n","                         u\"\\u23e9\"\n","                         u\"\\u231a\"\n","                         u\"\\ufe0f\"\n","                         u\"\\u3030\"\n","                         \"]+\", flags=re.UNICODE)\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\"\", regex=True)\n","    \n","    #removes numbers\n","    pattern = r'\\d+'\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\"\", regex=True)\n","    \n","    #removes punctuation\n","    pattern = r\"[^\\w\\s]\"\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\" \", regex=True)\n","\n","    #removes stop words\n","    stop_words = stopwords.words(\"english\")    \n","    remove_stop_words = lambda row: \" \".join([token for token in row.split(\" \")\n","                                              if token not in stop_words])\n","    df[\"tweet\"] = df[\"tweet\"].apply(remove_stop_words)\n","    \n","    #removes extra spaces\n","    pattern = r\"[\\s]+\"\n","    df[\"tweet\"] = df[\"tweet\"].str.replace(pat=pattern, repl=\" \", regex=True)\n","    \n","    return(df)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"ATUTCjFaaknr","executionInfo":{"status":"ok","timestamp":1607218447794,"user_tz":300,"elapsed":7597,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}}},"source":["def train_validate_test_split(df,seed, train_percent=.8, validate_percent=.125):\n","  train, test = train_test_split(df, train_size=train_percent, stratify=df['label'], random_state=seed)\n","  train, validate = train_test_split(train, test_size=validate_percent, stratify=train['label'], random_state=seed)\n","  return train, validate, test\n","\n","def sample_data(df,sample,seed):\n","    X_train, _, y_train, _ = train_test_split( df['tweet'], df['label'], train_size=sample, random_state=seed, stratify=df['label'])\n","    return pd.concat([X_train,y_train], axis = 1 )\n","\n","def tokenize_data(df):\n","    sentences = [\"[CLS] \" + query + \" [SEP]\" for query in df['tweet']]\n","    # Tokenize with multilingual BERT tokenizer\n","    tokenizer = BertTokenizer.from_pretrained('claudelkros/bert-base-french', do_lower_case=True)\n","    #tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n","    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","    \n","    MAX_LEN = 128\n","\n","    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n","    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n","                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","    # Create attention masks\n","    attention_masks = []\n","    # Create a mask of 1s for each token followed by 0s for padding\n","    for seq in input_ids:\n","        seq_mask = [float(i>0) for i in seq]\n","        attention_masks.append(seq_mask)\n","    return input_ids, attention_masks\n","\n","def Data_Loader(inputs_ids, attention_masks, df,batch_size=16): \n","    data = TensorDataset(torch.LongTensor(inputs_ids), torch.LongTensor(attention_masks), torch.LongTensor(df['label'].values))\n","    sampler = RandomSampler(data)\n","    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n","    return dataloader"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHohHSKIaq7b","executionInfo":{"status":"ok","timestamp":1607218447795,"user_tz":300,"elapsed":7593,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}}},"source":["def model_train(model, train_dataloader, validation_dataloader):\n","    # Store our loss and accuracy for plotting\n","    train_loss_set = []\n","    # BERT training loop\n","    epochs = 3\n","    for _ in trange(epochs, desc=\"Epoch\"):  \n","        # Set our model to training mode\n","        model.train()\n","        # Tracking variables\n","        tr_loss = 0\n","        nb_tr_examples, nb_tr_steps = 0, 0\n","        # Train the data for one epoch\n","        for step, batch in enumerate(train_dataloader):\n","            # Add batch to GPU\n","            batch = tuple(t.to(device) for t in batch)\n","            # Unpack the inputs from our dataloader\n","            b_input_ids, b_input_mask, b_labels = batch\n","            # Clear out the gradients (by default they accumulate)\n","            optimizer.zero_grad()\n","            # Forward pass\n","            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","            loss = outputs[\"loss\"]  \n","            # Backward pass\n","            loss.backward()\n","            # Update parameters and take a step using the computed gradient\n","            optimizer.step()\n","            # Update tracking variables\n","            tr_loss += loss.item()\n","            nb_tr_examples += b_input_ids.size(0)\n","            nb_tr_steps += 1\n","        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","\n","        ## VALIDATION\n","\n","        # Put model in evaluation mode\n","        model.eval()\n","        # Tracking variables \n","        eval_loss, eval_accuracy = 0, 0\n","        nb_eval_steps, nb_eval_examples = 0, 0\n","        # Evaluate data for one epoch\n","        for batch in validation_dataloader:\n","            # Add batch to GPU\n","            batch = tuple(t.to(device) for t in batch)\n","            # Unpack the inputs from our dataloader\n","            b_input_ids, b_input_mask, b_labels = batch\n","            # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","            with torch.no_grad():\n","              # Forward pass, calculate logit predictions\n","                logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","            # Move logits and labels to CPU\n","            logits = logits.detach().cpu().numpy()\n","            label_ids = b_labels.to('cpu').numpy()\n","            tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n","            eval_accuracy += tmp_eval_accuracy\n","            nb_eval_steps += 1\n","        validation_accuracy = (eval_accuracy/nb_eval_steps)\n","        print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","    return validation_accuracy"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fh9pHbFPax9h","executionInfo":{"status":"ok","timestamp":1607218447796,"user_tz":300,"elapsed":7590,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}}},"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","def model_test(model,prediction_dataloader):\n","    model.eval()\n","    # Tracking variables \n","    predictions , true_labels = [], []\n","# Predict\n","    for batch in prediction_dataloader:\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)[0]\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        predictions+=list(np.argmax(logits, axis=1).flatten())\n","        true_labels+=list(label_ids.flatten())\n","    test_f1_score = f1_score(true_labels, predictions, average= 'macro')\n","    print(\"Macro F1 Score:\",test_f1_score)\n","    test_f1_wscore = f1_score(true_labels, predictions, average= 'weighted')\n","    print(\"Weighted F1 Score:\",test_f1_wscore)\n","    test_accuracy_score = accuracy_score(true_labels, predictions)\n","    print(\"Accuracy score:\", test_accuracy_score, \"\\n\")\n","    print(\"=\"*100)\n","    return test_f1_score, test_f1_wscore"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"C84QhrtEa5xO","executionInfo":{"status":"ok","timestamp":1607218447796,"user_tz":300,"elapsed":7585,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}}},"source":["def model_initialise():\n","  # Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n","  model = BertForSequenceClassification.from_pretrained(\"claudelkros/bert-base-french\", num_labels=2).cuda()\n","  optimizer = optim.AdamW(params = model.parameters(), lr=2e-5)\n","  return model, optimizer"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxfLlgbVCCBv","executionInfo":{"status":"ok","timestamp":1607219266947,"user_tz":300,"elapsed":826730,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}},"outputId":"635659c9-0057-4805-eb7b-8136e609dde7"},"source":["print_stmts= []\n","languages = ['French']\n","directory = 'drive/My Drive/CS695'\n","for lang in languages:\n","  df = pd.read_csv(os.path.join(directory, lang+'.csv'))\n","  df = preprocess(df)\n","  sample_sizes = [16, 32, 64, 128, 256]\n","for sample in sample_sizes: \n","  seeds = [2018,2019, 2020, 2021, 2022]\n","  weighted = []\n","  macro = [] \n","  for seed in seeds:\n","    np.random.seed(seed)\n","    train_df, validation_df, test_df = train_validate_test_split(df, seed)\n","    train_len = len(train_df)\n","    if sample==256 and seed==2022:\n","        sample_sizes.append(train_len)\n","    if sample == train_len and seed == 2022:\n","        sample_sizes.remove(train_len)\n","    model, optimizer = model_initialise()\n","    if(sample != train_len):  \n","      train_df_sample = sample_data(train_df,sample,seed)\n","      train_input_ids, train_attention_masks = tokenize_data(train_df_sample)\n","      train_dataloader = Data_Loader(train_input_ids, train_attention_masks, train_df_sample)\n","    else:\n","      train_input_ids, train_attention_masks = tokenize_data(train_df)\n","      train_dataloader = Data_Loader(train_input_ids, train_attention_masks, train_df)\n","\n","    validation_input_ids, validation_attention_masks = tokenize_data(validation_df)\n","    validation_dataloader = Data_Loader(validation_input_ids, validation_attention_masks, validation_df)\n","    print(\"\\nModel Summary:\")\n","    print('Language:', lang)\n","    print('Sample Size:', sample)\n","    print('Seed value:', seed)\n","    validation_accuracy = model_train(model, train_dataloader, validation_dataloader)\n","    test_input_ids, test_attention_masks = tokenize_data(test_df)\n","    test_dataloader = Data_Loader(test_input_ids, test_attention_masks, test_df)\n","    m, w = model_test(model, test_dataloader)\n","    weighted.append(w)\n","    macro.append(m)\n","  print(\"The Average  Weighted F1-Score of the Language \", lang, \"is:\",sum(weighted)/ len(weighted))\n","  print(\"The Average  Macro F1-Score of the Language \", lang, \"is:\",sum(macro)/ len(macro))\n","  print(\"=\"*200)\n","  print_stmts.append(\"For Sample Size \"+str(sample)+\" Average Weighted F1-Score \"+str(sum(weighted)/len(weighted))+\" and Average Macro F1-Score \"+str(sum(macro)/len(macro))+\" of \"+ str(lang))\n","for i in print_stmts:\n","  print(i,\"\\n\")\n","print(\"=\"*100+str(lang)+\"=\"*100)"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 16\n","Seed value: 2018\n","Train loss: 0.8859320878982544\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.32it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.670242190361023\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.33it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6054714322090149\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 16\n","Seed value: 2019\n","Train loss: 0.7735915780067444\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.37it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6564949750900269\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.37it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6463449597358704\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6828125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 16\n","Seed value: 2020\n","Train loss: 0.6744892001152039\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.36it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n","Train loss: 0.6546728014945984\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.36it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6711809635162354\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 16\n","Seed value: 2021\n","Train loss: 0.6531351804733276\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.33it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n","Train loss: 0.6140158176422119\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.34it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6379990577697754\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 16\n","Seed value: 2022\n","Train loss: 0.6665301322937012\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.37it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.6054803133010864\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.37it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6333905458450317\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n","The Average  Weighted F1-Score of the Language  French is: 0.5403407264545163\n","The Average  Macro F1-Score of the Language  French is: 0.4019607843137255\n","========================================================================================================================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 32\n","Seed value: 2018\n","Train loss: 0.6063159704208374\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.03it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6214736104011536\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.04it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6828125\n","Train loss: 0.6486984193325043\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6828125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 32\n","Seed value: 2019\n","Train loss: 0.685387372970581\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.04it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n","Train loss: 0.6599052250385284\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.04it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6507891416549683\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 32\n","Seed value: 2020\n","Train loss: 0.7142337560653687\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.03it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6517786681652069\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.04it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6495911777019501\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 32\n","Seed value: 2021\n","Train loss: 0.6264722943305969\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.01it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6591464579105377\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.02it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6733832210302353\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 32\n","Seed value: 2022\n","Train loss: 0.7157362997531891\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:00<00:01,  1.03it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.6437872350215912\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:01<00:00,  1.04it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6510525345802307\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n","The Average  Weighted F1-Score of the Language  French is: 0.5403407264545163\n","The Average  Macro F1-Score of the Language  French is: 0.4019607843137255\n","========================================================================================================================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 64\n","Seed value: 2018\n","Train loss: 0.621903121471405\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6875\n","Train loss: 0.6498353779315948\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6401442885398865\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 64\n","Seed value: 2019\n","Train loss: 0.6446471810340881\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6828125\n","Train loss: 0.6552832573652267\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6557678580284119\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 64\n","Seed value: 2020\n","Train loss: 0.6573771834373474\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6711387634277344\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6593881696462631\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 64\n","Seed value: 2021\n","Train loss: 0.6595417708158493\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6858252882957458\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.6882237493991852\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 64\n","Seed value: 2022\n","Train loss: 0.6824494749307632\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.6727573722600937\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:02<00:01,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6272672116756439\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:04<00:00,  1.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n","The Average  Weighted F1-Score of the Language  French is: 0.5403407264545163\n","The Average  Macro F1-Score of the Language  French is: 0.4019607843137255\n","========================================================================================================================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 128\n","Seed value: 2018\n","Train loss: 0.7634487748146057\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.38s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.7122780978679657\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.37s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6619522720575333\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 128\n","Seed value: 2019\n","Train loss: 0.663764588534832\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6828125\n","Train loss: 0.6452324315905571\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n","Train loss: 0.633342795073986\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 128\n","Seed value: 2020\n","Train loss: 0.676876574754715\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.37s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6887956410646439\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.37s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6651778593659401\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 128\n","Seed value: 2021\n","Train loss: 0.6404877007007599\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6389166414737701\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6317020021378994\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 128\n","Seed value: 2022\n","Train loss: 0.6660014614462852\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:02<00:04,  2.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.6816177442669868\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:04<00:02,  2.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6588988304138184\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:07<00:00,  2.36s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n","The Average  Weighted F1-Score of the Language  French is: 0.5403407264545163\n","The Average  Macro F1-Score of the Language  French is: 0.4019607843137255\n","========================================================================================================================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 256\n","Seed value: 2018\n","Train loss: 0.6547456495463848\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.20s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6357721891254187\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.20s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6875\n","Train loss: 0.6754586901515722\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 256\n","Seed value: 2019\n","Train loss: 0.6898982413113117\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.6479288451373577\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.22s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6828125\n","Train loss: 0.6478442437946796\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.21s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 256\n","Seed value: 2020\n","Train loss: 0.6535668559372425\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.20s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6828125\n","Train loss: 0.6469384357333183\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.20s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6399582847952843\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.20s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 256\n","Seed value: 2021\n","Train loss: 0.6609774436801672\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6407509613782167\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n","Train loss: 0.6768679916858673\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.21s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6875\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 256\n","Seed value: 2022\n","Train loss: 0.6396927330642939\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:04<00:08,  4.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n","Train loss: 0.637790635228157\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:08<00:04,  4.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.6335782073438168\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:12<00:00,  4.21s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6546875\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n","The Average  Weighted F1-Score of the Language  French is: 0.5403407264545163\n","The Average  Macro F1-Score of the Language  French is: 0.4019607843137255\n","========================================================================================================================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 854\n","Seed value: 2018\n","Train loss: 0.6461985083641829\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:12<00:25, 12.87s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6411145633017575\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:25<00:12, 12.87s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.645343397502546\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:38<00:00, 12.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 854\n","Seed value: 2019\n","Train loss: 0.6587158971362643\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:12<00:25, 12.88s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.6373826866900479\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:25<00:12, 12.88s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n","Train loss: 0.6546482035407314\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:38<00:00, 12.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 854\n","Seed value: 2020\n","Train loss: 0.6434485448731316\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:12<00:25, 12.84s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.6528680214175472\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:25<00:12, 12.85s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n","Train loss: 0.6436443135694221\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:38<00:00, 12.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6828125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 854\n","Seed value: 2021\n","Train loss: 0.6473417696025636\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:12<00:25, 12.85s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6734375\n","Train loss: 0.652546665734715\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:25<00:12, 12.85s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.6640625\n","Train loss: 0.6422472982494919\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:38<00:00, 12.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at claudelkros/bert-base-french were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at claudelkros/bert-base-french and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\n","Epoch:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["\n","Model Summary:\n","Language: French\n","Sample Size: 854\n","Seed value: 2022\n","Train loss: 0.6684743132856157\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  33%|███▎      | 1/3 [00:12<00:25, 12.83s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n","Train loss: 0.6502071939132832\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch:  67%|██████▋   | 2/3 [00:25<00:12, 12.84s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.66875\n","Train loss: 0.6304918820107425\n"],"name":"stdout"},{"output_type":"stream","text":["\n","Epoch: 100%|██████████| 3/3 [00:38<00:00, 12.83s/it]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy: 0.678125\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Macro F1 Score: 0.40196078431372545\n","Weighted F1 Score: 0.5403407264545163\n","Accuracy score: 0.6721311475409836 \n","\n","====================================================================================================\n","The Average  Weighted F1-Score of the Language  French is: 0.5403407264545163\n","The Average  Macro F1-Score of the Language  French is: 0.4019607843137255\n","========================================================================================================================================================================================================\n","For Sample Size 16 Average Weighted F1-Score 0.5403407264545163 and Average Macro F1-Score 0.4019607843137255 of French \n","\n","For Sample Size 32 Average Weighted F1-Score 0.5403407264545163 and Average Macro F1-Score 0.4019607843137255 of French \n","\n","For Sample Size 64 Average Weighted F1-Score 0.5403407264545163 and Average Macro F1-Score 0.4019607843137255 of French \n","\n","For Sample Size 128 Average Weighted F1-Score 0.5403407264545163 and Average Macro F1-Score 0.4019607843137255 of French \n","\n","For Sample Size 256 Average Weighted F1-Score 0.5403407264545163 and Average Macro F1-Score 0.4019607843137255 of French \n","\n","For Sample Size 854 Average Weighted F1-Score 0.5403407264545163 and Average Macro F1-Score 0.4019607843137255 of French \n","\n","====================================================================================================French====================================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wey_mbaAC7F5","executionInfo":{"status":"ok","timestamp":1607219266948,"user_tz":300,"elapsed":826725,"user":{"displayName":"Sreenitha Kasarapu","photoUrl":"","userId":"11308003982662682363"}}},"source":[""],"execution_count":55,"outputs":[]}]}